{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMviZsoVG4n1/PtxgqbaMnt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujithcplusplus/facial_feature_mapping/blob/main/facial_feature_mapping_15_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8amNwkj2xvNL"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.image as img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define 'build_model' function which takes the dataframe and two column number for (x,y) to build a model and 'model_name' to save the model\n",
        "def build_model(df,col1,col2,model_name):\n",
        "  required_data = df.iloc[:, [ col1, col2, 30]].copy()\n",
        "  required_data.dropna(inplace=True)\n",
        "\n",
        "  Img_paths = required_data.iloc[:, -1]\n",
        "  y = required_data.iloc[:, :2]\n",
        "\n",
        "  X = []\n",
        "\n",
        "  for i in Img_paths:\n",
        "    itensor = tf.image.rgb_to_grayscale(tf.convert_to_tensor(Image.open(i),dtype=tf.float32))\n",
        "    X.append(itensor/255)\n",
        "  X = np.array(X)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split( X, y, test_size = 0.15,random_state = 42)\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,3,activation='relu',input_shape=(96,96,1)),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64,3,activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128,3,activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(256,3,activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(2,activation='linear'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 96)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss = 'mae',\n",
        "                optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001,momentum=0.9),\n",
        "                metrics = ['mae','mse'])\n",
        "  history = model.fit(X_train,y_train,epochs=50,validation_data = (X_val,y_val))\n",
        "\n",
        "  val_mae.append(history.history['val_mae'][-1])\n",
        "  val_mse.append(history.history['val_mse'][-1])\n",
        "\n",
        "  model.save(model_name)\n",
        "  return 0"
      ],
      "metadata": {
        "id": "R5orWMGm_Ui0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the training data read attach the file paths to coordinates dataframe.\n",
        "def setup():\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  zip_ref = zipfile.ZipFile('/content/drive/MyDrive/facial feature mapping project/Dataset.zip','r')\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "  data = pd.read_csv('training.csv')\n",
        "\n",
        "  paths = sorted(glob.glob('/content/images/train_images/*'))\n",
        "\n",
        "  data['paths'] = paths\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "yWhBKgjUIrGG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = setup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsGjM0FLJKnG",
        "outputId": "98c03568-1aac-4ed6-882e-7e067e1ad963"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hcXysgpCwiu",
        "outputId": "faddf0d3-dc89-4c9c-9968-ae2e6c1d9220"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7049 entries, 0 to 7048\n",
            "Data columns (total 31 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   left_eye_center_x          7039 non-null   float64\n",
            " 1   left_eye_center_y          7039 non-null   float64\n",
            " 2   right_eye_center_x         7036 non-null   float64\n",
            " 3   right_eye_center_y         7036 non-null   float64\n",
            " 4   left_eye_inner_corner_x    2271 non-null   float64\n",
            " 5   left_eye_inner_corner_y    2271 non-null   float64\n",
            " 6   left_eye_outer_corner_x    2267 non-null   float64\n",
            " 7   left_eye_outer_corner_y    2267 non-null   float64\n",
            " 8   right_eye_inner_corner_x   2268 non-null   float64\n",
            " 9   right_eye_inner_corner_y   2268 non-null   float64\n",
            " 10  right_eye_outer_corner_x   2268 non-null   float64\n",
            " 11  right_eye_outer_corner_y   2268 non-null   float64\n",
            " 12  left_eyebrow_inner_end_x   2270 non-null   float64\n",
            " 13  left_eyebrow_inner_end_y   2270 non-null   float64\n",
            " 14  left_eyebrow_outer_end_x   2225 non-null   float64\n",
            " 15  left_eyebrow_outer_end_y   2225 non-null   float64\n",
            " 16  right_eyebrow_inner_end_x  2270 non-null   float64\n",
            " 17  right_eyebrow_inner_end_y  2270 non-null   float64\n",
            " 18  right_eyebrow_outer_end_x  2236 non-null   float64\n",
            " 19  right_eyebrow_outer_end_y  2236 non-null   float64\n",
            " 20  nose_tip_x                 7049 non-null   float64\n",
            " 21  nose_tip_y                 7049 non-null   float64\n",
            " 22  mouth_left_corner_x        2269 non-null   float64\n",
            " 23  mouth_left_corner_y        2269 non-null   float64\n",
            " 24  mouth_right_corner_x       2270 non-null   float64\n",
            " 25  mouth_right_corner_y       2270 non-null   float64\n",
            " 26  mouth_center_top_lip_x     2275 non-null   float64\n",
            " 27  mouth_center_top_lip_y     2275 non-null   float64\n",
            " 28  mouth_center_bottom_lip_x  7016 non-null   float64\n",
            " 29  mouth_center_bottom_lip_y  7016 non-null   float64\n",
            " 30  paths                      7049 non-null   object \n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_mae = []\n",
        "val_mse = []"
      ],
      "metadata": {
        "id": "QvFN5b9y-sCh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['left_eye_center_model',\n",
        "               'right_eye_center_model',\n",
        "               'left_eye_inner_corner_model',\n",
        "               'left_eye_outer_corner_model',\n",
        "               'right_eye_inner_corner_model',\n",
        "               'right_eye_outer_corner_model',\n",
        "               'left_eyebrow_inner_end_model',\n",
        "               'left_eyebrow_outer_end_model',\n",
        "               'right_eyebrow_inner_end_model',\n",
        "               'right_eyebrow_outer_end_model',\n",
        "               'nose_tip_model',\n",
        "               'mouth_left_corner_model',\n",
        "               'mouth_right_corner_model',\n",
        "               'mouth_center_top_lip_model',\n",
        "               'mouth_center_bottom_lip'\n",
        "               ]"
      ],
      "metadata": {
        "id": "j0uHqd9YYIpY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,15)\n",
        "build_model(df,col1,col2,model_names[col1/2])\n",
        "col1+=2\n",
        "col2+=2\n",
        "col1,col2"
      ],
      "metadata": {
        "id": "1Zj6mUCOX35U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 15):\n",
        "    print(df.columns[2*i], df.columns[(2*i)+1], model_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wkUK7NQa_F4",
        "outputId": "6bce8098-d60a-47bc-c721-de6041b54ea0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "left_eye_center_x left_eye_center_y left_eye_center_model\n",
            "right_eye_center_x right_eye_center_y right_eye_center_model\n",
            "left_eye_inner_corner_x left_eye_inner_corner_y left_eye_inner_corner_model\n",
            "left_eye_outer_corner_x left_eye_outer_corner_y left_eye_outer_corner_model\n",
            "right_eye_inner_corner_x right_eye_inner_corner_y right_eye_inner_corner_model\n",
            "right_eye_outer_corner_x right_eye_outer_corner_y right_eye_outer_corner_model\n",
            "left_eyebrow_inner_end_x left_eyebrow_inner_end_y left_eyebrow_inner_end_model\n",
            "left_eyebrow_outer_end_x left_eyebrow_outer_end_y left_eyebrow_outer_end_model\n",
            "right_eyebrow_inner_end_x right_eyebrow_inner_end_y right_eyebrow_inner_end_model\n",
            "right_eyebrow_outer_end_x right_eyebrow_outer_end_y right_eyebrow_outer_end_model\n",
            "nose_tip_x nose_tip_y nose_tip_model\n",
            "mouth_left_corner_x mouth_left_corner_y mouth_left_corner_model\n",
            "mouth_right_corner_x mouth_right_corner_y mouth_right_corner_model\n",
            "mouth_center_top_lip_x mouth_center_top_lip_y mouth_center_top_lip_model\n",
            "mouth_center_bottom_lip_x mouth_center_bottom_lip_y mouth_center_bottom_lip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,15):\n",
        "  build_model(df,(2*i),(2*i)+1,model_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrPq-ncNb0wH",
        "outputId": "0a0b8ab2-34e9-4053-8fec-48779438aa51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "187/187 [==============================] - 13s 17ms/step - loss: 4.3971 - mae: 4.3971 - mse: 87.0293 - val_loss: 2.3773 - val_mae: 2.3773 - val_mse: 11.2913\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.3005 - mae: 2.3005 - mse: 11.8963 - val_loss: 2.6917 - val_mae: 2.6917 - val_mse: 13.0949\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2765 - mae: 2.2765 - mse: 11.7589 - val_loss: 2.4143 - val_mae: 2.4143 - val_mse: 11.5402\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2424 - mae: 2.2424 - mse: 11.5809 - val_loss: 2.0748 - val_mae: 2.0748 - val_mse: 9.8760\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2500 - mae: 2.2500 - mse: 11.6099 - val_loss: 2.1193 - val_mae: 2.1193 - val_mse: 9.9868\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2310 - mae: 2.2310 - mse: 11.5222 - val_loss: 2.1588 - val_mae: 2.1588 - val_mse: 10.4717\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2348 - mae: 2.2348 - mse: 11.5019 - val_loss: 2.0917 - val_mae: 2.0917 - val_mse: 10.0305\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2149 - mae: 2.2149 - mse: 11.3827 - val_loss: 2.0965 - val_mae: 2.0965 - val_mse: 10.0727\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.2078 - mae: 2.2078 - mse: 11.3562 - val_loss: 2.1350 - val_mae: 2.1350 - val_mse: 10.3590\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2191 - mae: 2.2191 - mse: 11.4383 - val_loss: 2.1696 - val_mae: 2.1696 - val_mse: 10.6545\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2037 - mae: 2.2037 - mse: 11.3343 - val_loss: 2.0772 - val_mae: 2.0772 - val_mse: 9.8583\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2025 - mae: 2.2025 - mse: 11.3179 - val_loss: 2.0755 - val_mae: 2.0755 - val_mse: 9.8900\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2119 - mae: 2.2119 - mse: 11.3761 - val_loss: 2.0749 - val_mae: 2.0749 - val_mse: 9.8575\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 2.2100 - mae: 2.2100 - mse: 11.3805 - val_loss: 2.0981 - val_mae: 2.0981 - val_mse: 10.0986\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 4s 20ms/step - loss: 2.2217 - mae: 2.2217 - mse: 11.4350 - val_loss: 2.0978 - val_mae: 2.0978 - val_mse: 9.9299\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2026 - mae: 2.2026 - mse: 11.3587 - val_loss: 2.0715 - val_mae: 2.0715 - val_mse: 9.8519\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2208 - mae: 2.2208 - mse: 11.4076 - val_loss: 2.0869 - val_mae: 2.0869 - val_mse: 9.8741\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2246 - mae: 2.2246 - mse: 11.4252 - val_loss: 2.0762 - val_mae: 2.0762 - val_mse: 9.8309\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2269 - mae: 2.2269 - mse: 11.4560 - val_loss: 2.0734 - val_mae: 2.0734 - val_mse: 9.8611\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2061 - mae: 2.2061 - mse: 11.3573 - val_loss: 2.1029 - val_mae: 2.1029 - val_mse: 10.0906\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2022 - mae: 2.2022 - mse: 11.3258 - val_loss: 2.1005 - val_mae: 2.1005 - val_mse: 10.0388\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2141 - mae: 2.2141 - mse: 11.4223 - val_loss: 2.2286 - val_mae: 2.2286 - val_mse: 10.4581\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2193 - mae: 2.2193 - mse: 11.4347 - val_loss: 2.1338 - val_mae: 2.1338 - val_mse: 10.0410\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2015 - mae: 2.2015 - mse: 11.3286 - val_loss: 2.1240 - val_mae: 2.1240 - val_mse: 10.2819\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2137 - mae: 2.2137 - mse: 11.4008 - val_loss: 2.0907 - val_mae: 2.0907 - val_mse: 9.9599\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2137 - mae: 2.2137 - mse: 11.3777 - val_loss: 2.0885 - val_mae: 2.0885 - val_mse: 9.8779\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.2147 - mae: 2.2147 - mse: 11.3862 - val_loss: 2.0939 - val_mae: 2.0939 - val_mse: 10.0529\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2109 - mae: 2.2109 - mse: 11.3935 - val_loss: 2.1364 - val_mae: 2.1364 - val_mse: 10.2059\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2178 - mae: 2.2178 - mse: 11.4478 - val_loss: 2.2013 - val_mae: 2.2013 - val_mse: 10.8582\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2537 - mae: 2.2537 - mse: 11.6092 - val_loss: 2.1655 - val_mae: 2.1655 - val_mse: 10.5431\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2227 - mae: 2.2227 - mse: 11.4757 - val_loss: 2.1374 - val_mae: 2.1374 - val_mse: 10.0870\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1945 - mae: 2.1945 - mse: 11.3194 - val_loss: 2.0752 - val_mae: 2.0752 - val_mse: 9.9131\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.2117 - mae: 2.2117 - mse: 11.3942 - val_loss: 2.0892 - val_mae: 2.0892 - val_mse: 10.0108\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2077 - mae: 2.2077 - mse: 11.3414 - val_loss: 2.0744 - val_mae: 2.0744 - val_mse: 9.8566\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2200 - mae: 2.2200 - mse: 11.4796 - val_loss: 2.1631 - val_mae: 2.1631 - val_mse: 10.3310\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2135 - mae: 2.2135 - mse: 11.4026 - val_loss: 2.0733 - val_mae: 2.0733 - val_mse: 9.8776\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2105 - mae: 2.2105 - mse: 11.4123 - val_loss: 2.1589 - val_mae: 2.1589 - val_mse: 10.1333\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2011 - mae: 2.2011 - mse: 11.3390 - val_loss: 2.1192 - val_mae: 2.1192 - val_mse: 10.2688\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.2122 - mae: 2.2122 - mse: 11.3817 - val_loss: 2.1010 - val_mae: 2.1010 - val_mse: 10.0332\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1957 - mae: 2.1957 - mse: 11.3229 - val_loss: 2.2005 - val_mae: 2.2005 - val_mse: 10.5037\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2081 - mae: 2.2081 - mse: 11.4131 - val_loss: 2.1552 - val_mae: 2.1552 - val_mse: 10.4875\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2119 - mae: 2.2119 - mse: 11.3630 - val_loss: 2.0853 - val_mae: 2.0853 - val_mse: 9.8557\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2009 - mae: 2.2009 - mse: 11.2994 - val_loss: 2.1246 - val_mae: 2.1246 - val_mse: 10.2858\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1964 - mae: 2.1964 - mse: 11.2862 - val_loss: 2.0887 - val_mae: 2.0887 - val_mse: 9.9467\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.2274 - mae: 2.2274 - mse: 11.5501 - val_loss: 2.1574 - val_mae: 2.1574 - val_mse: 10.3478\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2139 - mae: 2.2139 - mse: 11.3942 - val_loss: 2.1607 - val_mae: 2.1607 - val_mse: 10.3600\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2058 - mae: 2.2058 - mse: 11.3706 - val_loss: 2.1376 - val_mae: 2.1376 - val_mse: 10.2452\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2237 - mae: 2.2237 - mse: 11.4404 - val_loss: 2.1048 - val_mae: 2.1048 - val_mse: 10.0290\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.2121 - mae: 2.2121 - mse: 11.3937 - val_loss: 2.0846 - val_mae: 2.0846 - val_mse: 9.9137\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.2101 - mae: 2.2101 - mse: 11.3696 - val_loss: 2.1068 - val_mae: 2.1068 - val_mse: 10.1111\n",
            "Epoch 1/50\n",
            "187/187 [==============================] - 5s 17ms/step - loss: 3.0532 - mae: 3.0532 - mse: 32.1465 - val_loss: 2.2097 - val_mae: 2.2097 - val_mse: 11.4840\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.1412 - mae: 2.1412 - mse: 9.7571 - val_loss: 2.0800 - val_mae: 2.0800 - val_mse: 10.5408\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.1030 - mae: 2.1030 - mse: 9.5049 - val_loss: 2.0765 - val_mae: 2.0765 - val_mse: 10.4670\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1003 - mae: 2.1003 - mse: 9.4736 - val_loss: 2.0891 - val_mae: 2.0891 - val_mse: 10.6574\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0994 - mae: 2.0994 - mse: 9.5057 - val_loss: 2.1200 - val_mae: 2.1200 - val_mse: 10.5673\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0799 - mae: 2.0799 - mse: 9.3755 - val_loss: 2.0857 - val_mae: 2.0857 - val_mse: 10.4387\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.1144 - mae: 2.1144 - mse: 9.5862 - val_loss: 2.0895 - val_mae: 2.0895 - val_mse: 10.4634\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0852 - mae: 2.0852 - mse: 9.4156 - val_loss: 2.2644 - val_mae: 2.2644 - val_mse: 11.8480\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.1148 - mae: 2.1148 - mse: 9.6245 - val_loss: 2.0864 - val_mae: 2.0864 - val_mse: 10.4507\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1120 - mae: 2.1120 - mse: 9.6243 - val_loss: 2.1317 - val_mae: 2.1317 - val_mse: 10.9891\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0728 - mae: 2.0728 - mse: 9.3839 - val_loss: 2.0777 - val_mae: 2.0777 - val_mse: 10.5417\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 2.1019 - mae: 2.1019 - mse: 9.5448 - val_loss: 2.1159 - val_mae: 2.1159 - val_mse: 10.5303\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0943 - mae: 2.0943 - mse: 9.4486 - val_loss: 2.1493 - val_mae: 2.1493 - val_mse: 10.6802\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0937 - mae: 2.0937 - mse: 9.4950 - val_loss: 2.2023 - val_mae: 2.2023 - val_mse: 10.8979\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0789 - mae: 2.0789 - mse: 9.3866 - val_loss: 2.0902 - val_mae: 2.0902 - val_mse: 10.5328\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0850 - mae: 2.0850 - mse: 9.4074 - val_loss: 2.1010 - val_mae: 2.1010 - val_mse: 10.5701\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.1125 - mae: 2.1125 - mse: 9.5596 - val_loss: 2.0918 - val_mae: 2.0918 - val_mse: 10.4398\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0899 - mae: 2.0899 - mse: 9.4666 - val_loss: 2.0711 - val_mae: 2.0711 - val_mse: 10.4717\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0823 - mae: 2.0823 - mse: 9.4088 - val_loss: 2.1006 - val_mae: 2.1006 - val_mse: 10.7711\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0732 - mae: 2.0732 - mse: 9.3567 - val_loss: 2.0807 - val_mae: 2.0807 - val_mse: 10.5938\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0806 - mae: 2.0806 - mse: 9.3684 - val_loss: 2.1301 - val_mae: 2.1301 - val_mse: 10.9495\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0826 - mae: 2.0826 - mse: 9.4042 - val_loss: 2.0914 - val_mae: 2.0914 - val_mse: 10.5280\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.1072 - mae: 2.1072 - mse: 9.5184 - val_loss: 2.1396 - val_mae: 2.1396 - val_mse: 10.6262\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0789 - mae: 2.0789 - mse: 9.3906 - val_loss: 2.0766 - val_mae: 2.0766 - val_mse: 10.4212\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0804 - mae: 2.0804 - mse: 9.4041 - val_loss: 2.1723 - val_mae: 2.1723 - val_mse: 10.8495\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0873 - mae: 2.0873 - mse: 9.4248 - val_loss: 2.1479 - val_mae: 2.1479 - val_mse: 10.7509\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.1015 - mae: 2.1015 - mse: 9.4919 - val_loss: 2.0715 - val_mae: 2.0715 - val_mse: 10.4823\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0680 - mae: 2.0680 - mse: 9.2690 - val_loss: 2.1613 - val_mae: 2.1613 - val_mse: 10.7317\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0905 - mae: 2.0905 - mse: 9.4738 - val_loss: 2.0750 - val_mae: 2.0750 - val_mse: 10.5256\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0740 - mae: 2.0740 - mse: 9.3512 - val_loss: 2.0795 - val_mae: 2.0795 - val_mse: 10.5138\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0712 - mae: 2.0712 - mse: 9.3121 - val_loss: 2.1464 - val_mae: 2.1464 - val_mse: 10.9580\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0656 - mae: 2.0656 - mse: 9.3190 - val_loss: 2.1252 - val_mae: 2.1252 - val_mse: 10.5512\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0658 - mae: 2.0658 - mse: 9.3119 - val_loss: 2.1098 - val_mae: 2.1098 - val_mse: 10.5031\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0863 - mae: 2.0863 - mse: 9.4185 - val_loss: 2.1217 - val_mae: 2.1217 - val_mse: 10.5461\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0724 - mae: 2.0724 - mse: 9.3503 - val_loss: 2.1171 - val_mae: 2.1171 - val_mse: 10.6375\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.1144 - mae: 2.1144 - mse: 9.5458 - val_loss: 2.0851 - val_mae: 2.0851 - val_mse: 10.5328\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0884 - mae: 2.0884 - mse: 9.4556 - val_loss: 2.1201 - val_mae: 2.1201 - val_mse: 10.6204\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0708 - mae: 2.0708 - mse: 9.3351 - val_loss: 2.0830 - val_mae: 2.0830 - val_mse: 10.5057\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0755 - mae: 2.0755 - mse: 9.3446 - val_loss: 2.1099 - val_mae: 2.1099 - val_mse: 10.4904\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0845 - mae: 2.0845 - mse: 9.3919 - val_loss: 2.2525 - val_mae: 2.2525 - val_mse: 11.2868\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0681 - mae: 2.0681 - mse: 9.3245 - val_loss: 2.1085 - val_mae: 2.1085 - val_mse: 10.8487\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0777 - mae: 2.0777 - mse: 9.3670 - val_loss: 2.1364 - val_mae: 2.1364 - val_mse: 11.0386\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0699 - mae: 2.0699 - mse: 9.3319 - val_loss: 2.0955 - val_mae: 2.0955 - val_mse: 10.6317\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0897 - mae: 2.0897 - mse: 9.4629 - val_loss: 2.0825 - val_mae: 2.0825 - val_mse: 10.4457\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0637 - mae: 2.0637 - mse: 9.3148 - val_loss: 2.0711 - val_mae: 2.0711 - val_mse: 10.4558\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0654 - mae: 2.0654 - mse: 9.3303 - val_loss: 2.0781 - val_mae: 2.0781 - val_mse: 10.6024\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.1005 - mae: 2.1005 - mse: 9.4864 - val_loss: 2.0794 - val_mae: 2.0794 - val_mse: 10.5408\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 2.0698 - mae: 2.0698 - mse: 9.3611 - val_loss: 2.0982 - val_mae: 2.0982 - val_mse: 10.6183\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 2.0819 - mae: 2.0819 - mse: 9.4211 - val_loss: 2.2284 - val_mae: 2.2284 - val_mse: 11.3996\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 3s 14ms/step - loss: 2.0861 - mae: 2.0861 - mse: 9.4281 - val_loss: 2.1123 - val_mae: 2.1123 - val_mse: 10.8601\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 3s 24ms/step - loss: 6.7983 - mae: 6.7983 - mse: 152.6015 - val_loss: 4.9144 - val_mae: 4.9144 - val_mse: 34.0536\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8817 - mae: 1.8817 - mse: 7.4249 - val_loss: 3.3991 - val_mae: 3.3991 - val_mse: 16.8237\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.8890 - mae: 1.8890 - mse: 7.3753 - val_loss: 1.9414 - val_mae: 1.9414 - val_mse: 7.8531\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.8238 - mae: 1.8238 - mse: 7.1336 - val_loss: 2.2830 - val_mae: 2.2830 - val_mse: 9.7092\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7737 - mae: 1.7737 - mse: 6.8074 - val_loss: 2.1271 - val_mae: 2.1271 - val_mse: 8.8669\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8212 - mae: 1.8212 - mse: 7.0417 - val_loss: 1.7061 - val_mae: 1.7061 - val_mse: 6.8518\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7702 - mae: 1.7702 - mse: 6.8349 - val_loss: 1.7721 - val_mae: 1.7721 - val_mse: 7.1498\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7884 - mae: 1.7884 - mse: 6.9115 - val_loss: 1.7961 - val_mae: 1.7961 - val_mse: 7.2737\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6952 - mae: 1.6952 - mse: 6.4724 - val_loss: 1.6747 - val_mae: 1.6747 - val_mse: 6.7453\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7060 - mae: 1.7060 - mse: 6.4438 - val_loss: 1.7988 - val_mae: 1.7988 - val_mse: 7.4019\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.7246 - mae: 1.7246 - mse: 6.5960 - val_loss: 1.7520 - val_mae: 1.7520 - val_mse: 7.1992\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.7243 - mae: 1.7243 - mse: 6.5399 - val_loss: 1.7767 - val_mae: 1.7767 - val_mse: 7.2989\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.7144 - mae: 1.7144 - mse: 6.5528 - val_loss: 1.6706 - val_mae: 1.6706 - val_mse: 6.7727\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6817 - mae: 1.6817 - mse: 6.4015 - val_loss: 1.6728 - val_mae: 1.6728 - val_mse: 6.7362\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.7036 - mae: 1.7036 - mse: 6.5035 - val_loss: 1.7498 - val_mae: 1.7498 - val_mse: 7.1985\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.7139 - mae: 1.7139 - mse: 6.5445 - val_loss: 1.7518 - val_mae: 1.7518 - val_mse: 7.1194\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6870 - mae: 1.6870 - mse: 6.4523 - val_loss: 1.6761 - val_mae: 1.6761 - val_mse: 6.7754\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7081 - mae: 1.7081 - mse: 6.4404 - val_loss: 1.6658 - val_mae: 1.6658 - val_mse: 6.7429\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7028 - mae: 1.7028 - mse: 6.5133 - val_loss: 1.8739 - val_mae: 1.8739 - val_mse: 7.6286\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6963 - mae: 1.6963 - mse: 6.4512 - val_loss: 1.7189 - val_mae: 1.7189 - val_mse: 6.9639\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6933 - mae: 1.6933 - mse: 6.4273 - val_loss: 1.8504 - val_mae: 1.8504 - val_mse: 7.6756\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6990 - mae: 1.6990 - mse: 6.4788 - val_loss: 1.8838 - val_mae: 1.8838 - val_mse: 7.8541\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6941 - mae: 1.6941 - mse: 6.4593 - val_loss: 1.6882 - val_mae: 1.6882 - val_mse: 6.7707\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6701 - mae: 1.6701 - mse: 6.3026 - val_loss: 1.6555 - val_mae: 1.6555 - val_mse: 6.6852\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6703 - mae: 1.6703 - mse: 6.3631 - val_loss: 1.6872 - val_mae: 1.6872 - val_mse: 6.8867\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6930 - mae: 1.6930 - mse: 6.4067 - val_loss: 1.6601 - val_mae: 1.6601 - val_mse: 6.7023\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6966 - mae: 1.6966 - mse: 6.5144 - val_loss: 1.7099 - val_mae: 1.7099 - val_mse: 7.0102\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6778 - mae: 1.6778 - mse: 6.3132 - val_loss: 1.6674 - val_mae: 1.6674 - val_mse: 6.7613\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6875 - mae: 1.6875 - mse: 6.4449 - val_loss: 1.6586 - val_mae: 1.6586 - val_mse: 6.6760\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6572 - mae: 1.6572 - mse: 6.2433 - val_loss: 1.7278 - val_mae: 1.7278 - val_mse: 6.9493\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 1.6818 - mae: 1.6818 - mse: 6.3912 - val_loss: 1.6665 - val_mae: 1.6665 - val_mse: 6.7694\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6783 - mae: 1.6783 - mse: 6.3983 - val_loss: 1.9292 - val_mae: 1.9292 - val_mse: 7.7910\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6709 - mae: 1.6709 - mse: 6.3327 - val_loss: 1.6549 - val_mae: 1.6549 - val_mse: 6.6903\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6937 - mae: 1.6937 - mse: 6.4270 - val_loss: 1.7035 - val_mae: 1.7035 - val_mse: 6.8244\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7398 - mae: 1.7398 - mse: 6.5851 - val_loss: 1.7139 - val_mae: 1.7139 - val_mse: 6.9468\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7010 - mae: 1.7010 - mse: 6.4120 - val_loss: 1.6892 - val_mae: 1.6892 - val_mse: 6.7841\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7032 - mae: 1.7032 - mse: 6.4651 - val_loss: 1.7732 - val_mae: 1.7732 - val_mse: 7.1554\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6811 - mae: 1.6811 - mse: 6.3369 - val_loss: 1.6833 - val_mae: 1.6833 - val_mse: 6.8365\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7187 - mae: 1.7187 - mse: 6.5462 - val_loss: 1.7684 - val_mae: 1.7684 - val_mse: 7.0965\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7321 - mae: 1.7321 - mse: 6.6392 - val_loss: 1.7557 - val_mae: 1.7557 - val_mse: 7.0571\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7152 - mae: 1.7152 - mse: 6.5257 - val_loss: 1.7660 - val_mae: 1.7660 - val_mse: 7.2938\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7246 - mae: 1.7246 - mse: 6.5709 - val_loss: 1.6740 - val_mae: 1.6740 - val_mse: 6.7841\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7055 - mae: 1.7055 - mse: 6.4856 - val_loss: 1.6880 - val_mae: 1.6880 - val_mse: 6.7689\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.7547 - mae: 1.7547 - mse: 6.7760 - val_loss: 1.6626 - val_mae: 1.6626 - val_mse: 6.7411\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.6777 - mae: 1.6777 - mse: 6.3102 - val_loss: 1.6977 - val_mae: 1.6977 - val_mse: 6.8152\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6789 - mae: 1.6789 - mse: 6.3330 - val_loss: 1.6546 - val_mae: 1.6546 - val_mse: 6.6527\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6900 - mae: 1.6900 - mse: 6.4233 - val_loss: 1.7176 - val_mae: 1.7176 - val_mse: 7.0003\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6791 - mae: 1.6791 - mse: 6.3958 - val_loss: 1.6711 - val_mae: 1.6711 - val_mse: 6.7861\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6715 - mae: 1.6715 - mse: 6.3397 - val_loss: 1.6669 - val_mae: 1.6669 - val_mse: 6.6949\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 1.6670 - mae: 1.6670 - mse: 6.3135 - val_loss: 1.8885 - val_mae: 1.8885 - val_mse: 7.5756\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 22ms/step - loss: 8.2940 - mae: 8.2940 - mse: 236.5932 - val_loss: 5.7017 - val_mae: 5.7017 - val_mse: 43.8771\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.4731 - mae: 2.4731 - mse: 12.0822 - val_loss: 4.2996 - val_mae: 4.2996 - val_mse: 27.6604\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3833 - mae: 2.3833 - mse: 11.3813 - val_loss: 4.6390 - val_mae: 4.6390 - val_mse: 28.5934\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.5429 - mae: 2.5429 - mse: 12.4224 - val_loss: 3.0364 - val_mae: 3.0364 - val_mse: 15.8274\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2937 - mae: 2.2937 - mse: 10.8137 - val_loss: 3.6085 - val_mae: 3.6085 - val_mse: 19.9873\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3242 - mae: 2.3242 - mse: 10.9877 - val_loss: 2.9430 - val_mae: 2.9430 - val_mse: 14.8317\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2485 - mae: 2.2485 - mse: 10.6138 - val_loss: 3.3714 - val_mae: 3.3714 - val_mse: 18.3254\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3116 - mae: 2.3116 - mse: 11.0282 - val_loss: 2.9516 - val_mae: 2.9516 - val_mse: 14.6746\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2546 - mae: 2.2546 - mse: 10.6094 - val_loss: 2.2004 - val_mae: 2.2004 - val_mse: 9.4962\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2814 - mae: 2.2814 - mse: 10.8398 - val_loss: 2.2808 - val_mae: 2.2808 - val_mse: 10.2108\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2391 - mae: 2.2391 - mse: 10.5987 - val_loss: 2.2929 - val_mae: 2.2929 - val_mse: 10.4080\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2298 - mae: 2.2298 - mse: 10.4613 - val_loss: 2.1753 - val_mae: 2.1753 - val_mse: 9.4211\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2444 - mae: 2.2444 - mse: 10.5721 - val_loss: 2.3859 - val_mae: 2.3859 - val_mse: 10.7794\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.2254 - mae: 2.2254 - mse: 10.4539 - val_loss: 2.5721 - val_mae: 2.5721 - val_mse: 12.2921\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2524 - mae: 2.2524 - mse: 10.5346 - val_loss: 2.1850 - val_mae: 2.1850 - val_mse: 9.4306\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2430 - mae: 2.2430 - mse: 10.5840 - val_loss: 2.1498 - val_mae: 2.1498 - val_mse: 9.2571\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2268 - mae: 2.2268 - mse: 10.5152 - val_loss: 2.3225 - val_mae: 2.3225 - val_mse: 10.4916\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2076 - mae: 2.2076 - mse: 10.3515 - val_loss: 2.5382 - val_mae: 2.5382 - val_mse: 11.8505\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2814 - mae: 2.2814 - mse: 10.8223 - val_loss: 2.4572 - val_mae: 2.4572 - val_mse: 11.5170\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2385 - mae: 2.2385 - mse: 10.5548 - val_loss: 2.1305 - val_mae: 2.1305 - val_mse: 9.0921\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2087 - mae: 2.2087 - mse: 10.4431 - val_loss: 2.4277 - val_mae: 2.4277 - val_mse: 11.3084\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3076 - mae: 2.3076 - mse: 10.9901 - val_loss: 2.4974 - val_mae: 2.4974 - val_mse: 11.6840\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2472 - mae: 2.2472 - mse: 10.5923 - val_loss: 2.1593 - val_mae: 2.1593 - val_mse: 9.3349\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2217 - mae: 2.2217 - mse: 10.4625 - val_loss: 2.3462 - val_mae: 2.3462 - val_mse: 10.6866\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2556 - mae: 2.2556 - mse: 10.6581 - val_loss: 2.1891 - val_mae: 2.1891 - val_mse: 9.3484\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2262 - mae: 2.2262 - mse: 10.4471 - val_loss: 2.3153 - val_mae: 2.3153 - val_mse: 10.4254\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2173 - mae: 2.2173 - mse: 10.4500 - val_loss: 2.3816 - val_mae: 2.3816 - val_mse: 10.6395\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2164 - mae: 2.2164 - mse: 10.4107 - val_loss: 2.4079 - val_mae: 2.4079 - val_mse: 11.1960\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2491 - mae: 2.2491 - mse: 10.6791 - val_loss: 2.2362 - val_mae: 2.2362 - val_mse: 9.9457\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1812 - mae: 2.1812 - mse: 10.2660 - val_loss: 2.2059 - val_mae: 2.2059 - val_mse: 9.7508\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2104 - mae: 2.2104 - mse: 10.4229 - val_loss: 2.1662 - val_mae: 2.1662 - val_mse: 9.3571\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2068 - mae: 2.2068 - mse: 10.4227 - val_loss: 2.1769 - val_mae: 2.1769 - val_mse: 9.3028\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2668 - mae: 2.2668 - mse: 10.7898 - val_loss: 2.3134 - val_mae: 2.3134 - val_mse: 10.3607\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2275 - mae: 2.2275 - mse: 10.5202 - val_loss: 2.2719 - val_mae: 2.2719 - val_mse: 10.0838\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2095 - mae: 2.2095 - mse: 10.3230 - val_loss: 2.1427 - val_mae: 2.1427 - val_mse: 9.1488\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1994 - mae: 2.1994 - mse: 10.4157 - val_loss: 2.2519 - val_mae: 2.2519 - val_mse: 9.9154\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2111 - mae: 2.2111 - mse: 10.4135 - val_loss: 2.2756 - val_mae: 2.2756 - val_mse: 10.2740\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2148 - mae: 2.2148 - mse: 10.4264 - val_loss: 2.1545 - val_mae: 2.1545 - val_mse: 9.3029\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1971 - mae: 2.1971 - mse: 10.3529 - val_loss: 2.1162 - val_mae: 2.1162 - val_mse: 8.9192\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2271 - mae: 2.2271 - mse: 10.4570 - val_loss: 2.1412 - val_mae: 2.1412 - val_mse: 9.0530\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2074 - mae: 2.2074 - mse: 10.3696 - val_loss: 2.4350 - val_mae: 2.4350 - val_mse: 11.2898\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2630 - mae: 2.2630 - mse: 10.5958 - val_loss: 2.3131 - val_mae: 2.3131 - val_mse: 10.0377\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2053 - mae: 2.2053 - mse: 10.3565 - val_loss: 2.1462 - val_mae: 2.1462 - val_mse: 9.0993\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2291 - mae: 2.2291 - mse: 10.5060 - val_loss: 2.2127 - val_mae: 2.2127 - val_mse: 9.5305\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2094 - mae: 2.2094 - mse: 10.3517 - val_loss: 2.1359 - val_mae: 2.1359 - val_mse: 8.9368\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2091 - mae: 2.2091 - mse: 10.4062 - val_loss: 2.1181 - val_mae: 2.1181 - val_mse: 8.9374\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1787 - mae: 2.1787 - mse: 10.2209 - val_loss: 2.1230 - val_mae: 2.1230 - val_mse: 8.9814\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1822 - mae: 2.1822 - mse: 10.2883 - val_loss: 2.1742 - val_mae: 2.1742 - val_mse: 9.3248\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2034 - mae: 2.2034 - mse: 10.3230 - val_loss: 2.1855 - val_mae: 2.1855 - val_mse: 9.5299\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2198 - mae: 2.2198 - mse: 10.4608 - val_loss: 2.2971 - val_mae: 2.2971 - val_mse: 10.4069\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 22ms/step - loss: 5.3058 - mae: 5.3058 - mse: 78.2511 - val_loss: 1.6182 - val_mae: 1.6182 - val_mse: 6.5864\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6776 - mae: 1.6776 - mse: 5.8390 - val_loss: 1.9222 - val_mae: 1.9222 - val_mse: 8.0512\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6503 - mae: 1.6503 - mse: 5.7873 - val_loss: 1.6068 - val_mae: 1.6068 - val_mse: 6.5280\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.6440 - mae: 1.6440 - mse: 5.6896 - val_loss: 1.6716 - val_mae: 1.6716 - val_mse: 6.7168\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6319 - mae: 1.6319 - mse: 5.6536 - val_loss: 1.5353 - val_mae: 1.5353 - val_mse: 6.1757\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5985 - mae: 1.5985 - mse: 5.5100 - val_loss: 1.5369 - val_mae: 1.5369 - val_mse: 6.1711\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5970 - mae: 1.5970 - mse: 5.4874 - val_loss: 2.4138 - val_mae: 2.4138 - val_mse: 10.7271\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.6703 - mae: 1.6703 - mse: 5.7645 - val_loss: 1.5808 - val_mae: 1.5808 - val_mse: 6.3803\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5867 - mae: 1.5867 - mse: 5.4547 - val_loss: 1.5301 - val_mae: 1.5301 - val_mse: 6.1475\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6552 - mae: 1.6552 - mse: 5.8314 - val_loss: 1.6974 - val_mae: 1.6974 - val_mse: 6.9599\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6275 - mae: 1.6275 - mse: 5.5801 - val_loss: 1.6918 - val_mae: 1.6918 - val_mse: 6.9018\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5807 - mae: 1.5807 - mse: 5.4451 - val_loss: 1.6144 - val_mae: 1.6144 - val_mse: 6.5216\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6332 - mae: 1.6332 - mse: 5.6459 - val_loss: 1.5674 - val_mae: 1.5674 - val_mse: 6.3206\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6025 - mae: 1.6025 - mse: 5.5607 - val_loss: 1.6255 - val_mae: 1.6255 - val_mse: 6.6149\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5758 - mae: 1.5758 - mse: 5.3987 - val_loss: 1.5821 - val_mae: 1.5821 - val_mse: 6.3791\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6296 - mae: 1.6296 - mse: 5.6443 - val_loss: 1.5344 - val_mae: 1.5344 - val_mse: 6.1623\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5863 - mae: 1.5863 - mse: 5.4818 - val_loss: 1.5424 - val_mae: 1.5424 - val_mse: 6.1683\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5909 - mae: 1.5909 - mse: 5.4846 - val_loss: 1.5366 - val_mae: 1.5366 - val_mse: 6.1620\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5872 - mae: 1.5872 - mse: 5.4406 - val_loss: 1.5589 - val_mae: 1.5589 - val_mse: 6.2584\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6010 - mae: 1.6010 - mse: 5.5094 - val_loss: 1.5644 - val_mae: 1.5644 - val_mse: 6.2543\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6156 - mae: 1.6156 - mse: 5.6156 - val_loss: 1.5635 - val_mae: 1.5635 - val_mse: 6.3061\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6813 - mae: 1.6813 - mse: 5.9087 - val_loss: 1.6074 - val_mae: 1.6074 - val_mse: 6.4700\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6154 - mae: 1.6154 - mse: 5.6170 - val_loss: 1.5528 - val_mae: 1.5528 - val_mse: 6.2522\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5695 - mae: 1.5695 - mse: 5.3809 - val_loss: 1.5805 - val_mae: 1.5805 - val_mse: 6.3871\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.6358 - mae: 1.6358 - mse: 5.6889 - val_loss: 1.5525 - val_mae: 1.5525 - val_mse: 6.1763\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5781 - mae: 1.5781 - mse: 5.4306 - val_loss: 1.5380 - val_mae: 1.5380 - val_mse: 6.1689\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5960 - mae: 1.5960 - mse: 5.4908 - val_loss: 1.6859 - val_mae: 1.6859 - val_mse: 6.8853\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5701 - mae: 1.5701 - mse: 5.4350 - val_loss: 1.5576 - val_mae: 1.5576 - val_mse: 6.2085\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5786 - mae: 1.5786 - mse: 5.4078 - val_loss: 1.6334 - val_mae: 1.6334 - val_mse: 6.5762\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.5971 - mae: 1.5971 - mse: 5.4783 - val_loss: 1.5314 - val_mae: 1.5314 - val_mse: 6.1534\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6045 - mae: 1.6045 - mse: 5.5719 - val_loss: 1.5900 - val_mae: 1.5900 - val_mse: 6.4074\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5863 - mae: 1.5863 - mse: 5.4697 - val_loss: 1.5785 - val_mae: 1.5785 - val_mse: 6.2970\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5727 - mae: 1.5727 - mse: 5.3752 - val_loss: 1.6524 - val_mae: 1.6524 - val_mse: 6.5228\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6567 - mae: 1.6567 - mse: 5.7996 - val_loss: 1.6058 - val_mae: 1.6058 - val_mse: 6.4353\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5990 - mae: 1.5990 - mse: 5.5277 - val_loss: 1.5865 - val_mae: 1.5865 - val_mse: 6.3171\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5860 - mae: 1.5860 - mse: 5.4767 - val_loss: 1.5460 - val_mae: 1.5460 - val_mse: 6.2114\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5793 - mae: 1.5793 - mse: 5.4444 - val_loss: 1.5241 - val_mae: 1.5241 - val_mse: 6.1173\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5806 - mae: 1.5806 - mse: 5.4272 - val_loss: 1.6123 - val_mae: 1.6123 - val_mse: 6.5167\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5788 - mae: 1.5788 - mse: 5.4396 - val_loss: 1.5283 - val_mae: 1.5283 - val_mse: 6.1450\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.6231 - mae: 1.6231 - mse: 5.6905 - val_loss: 1.6383 - val_mae: 1.6383 - val_mse: 6.6343\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5789 - mae: 1.5789 - mse: 5.4604 - val_loss: 1.5307 - val_mae: 1.5307 - val_mse: 6.0996\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5662 - mae: 1.5662 - mse: 5.3513 - val_loss: 1.5171 - val_mae: 1.5171 - val_mse: 6.0645\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5859 - mae: 1.5859 - mse: 5.5183 - val_loss: 1.5219 - val_mae: 1.5219 - val_mse: 6.1076\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.5754 - mae: 1.5754 - mse: 5.4134 - val_loss: 1.6118 - val_mae: 1.6118 - val_mse: 6.4716\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.5876 - mae: 1.5876 - mse: 5.4965 - val_loss: 1.5211 - val_mae: 1.5211 - val_mse: 6.1045\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5986 - mae: 1.5986 - mse: 5.5110 - val_loss: 1.7034 - val_mae: 1.7034 - val_mse: 6.9732\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.6070 - mae: 1.6070 - mse: 5.5378 - val_loss: 1.6166 - val_mae: 1.6166 - val_mse: 6.3808\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 1.5858 - mae: 1.5858 - mse: 5.4391 - val_loss: 1.7049 - val_mae: 1.7049 - val_mse: 6.8187\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.5739 - mae: 1.5739 - mse: 5.3990 - val_loss: 1.5449 - val_mae: 1.5449 - val_mse: 6.1570\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 1.6158 - mae: 1.6158 - mse: 5.5714 - val_loss: 1.6462 - val_mae: 1.6462 - val_mse: 6.5680\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 19ms/step - loss: 4.9596 - mae: 4.9596 - mse: 64.4427 - val_loss: 2.6697 - val_mae: 2.6697 - val_mse: 11.9616\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3343 - mae: 2.3343 - mse: 10.1972 - val_loss: 2.5897 - val_mae: 2.5897 - val_mse: 11.1658\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2582 - mae: 2.2582 - mse: 9.6512 - val_loss: 2.1445 - val_mae: 2.1445 - val_mse: 8.6975\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2437 - mae: 2.2437 - mse: 9.4630 - val_loss: 2.4351 - val_mae: 2.4351 - val_mse: 10.2866\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2243 - mae: 2.2243 - mse: 9.4635 - val_loss: 2.2867 - val_mae: 2.2867 - val_mse: 9.4367\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2593 - mae: 2.2593 - mse: 9.6339 - val_loss: 2.2707 - val_mae: 2.2707 - val_mse: 9.3936\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1836 - mae: 2.1836 - mse: 9.1585 - val_loss: 2.1574 - val_mae: 2.1574 - val_mse: 8.8805\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1872 - mae: 2.1872 - mse: 9.2365 - val_loss: 2.1574 - val_mae: 2.1574 - val_mse: 8.9586\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2333 - mae: 2.2333 - mse: 9.4803 - val_loss: 2.2084 - val_mae: 2.2084 - val_mse: 9.0055\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.1970 - mae: 2.1970 - mse: 9.2433 - val_loss: 2.3168 - val_mae: 2.3168 - val_mse: 9.6252\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2013 - mae: 2.2013 - mse: 9.2976 - val_loss: 2.1395 - val_mae: 2.1395 - val_mse: 8.6779\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2097 - mae: 2.2097 - mse: 9.3396 - val_loss: 2.1752 - val_mae: 2.1752 - val_mse: 9.0626\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1997 - mae: 2.1997 - mse: 9.3330 - val_loss: 2.2112 - val_mae: 2.2112 - val_mse: 9.0415\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2170 - mae: 2.2170 - mse: 9.3817 - val_loss: 2.1352 - val_mae: 2.1352 - val_mse: 8.7480\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2108 - mae: 2.2108 - mse: 9.2991 - val_loss: 2.1558 - val_mae: 2.1558 - val_mse: 8.7581\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2566 - mae: 2.2566 - mse: 9.5350 - val_loss: 2.2012 - val_mae: 2.2012 - val_mse: 8.9747\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1824 - mae: 2.1824 - mse: 9.0911 - val_loss: 2.1273 - val_mae: 2.1273 - val_mse: 8.7205\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2121 - mae: 2.2121 - mse: 9.3111 - val_loss: 2.1449 - val_mae: 2.1449 - val_mse: 8.6940\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1934 - mae: 2.1934 - mse: 9.2151 - val_loss: 2.1437 - val_mae: 2.1437 - val_mse: 8.9418\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1964 - mae: 2.1964 - mse: 9.2683 - val_loss: 2.1483 - val_mae: 2.1483 - val_mse: 8.7092\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2174 - mae: 2.2174 - mse: 9.3508 - val_loss: 2.4275 - val_mae: 2.4275 - val_mse: 10.2073\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1927 - mae: 2.1927 - mse: 9.2909 - val_loss: 2.1270 - val_mae: 2.1270 - val_mse: 8.6757\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2053 - mae: 2.2053 - mse: 9.3686 - val_loss: 2.1340 - val_mae: 2.1340 - val_mse: 8.6483\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1763 - mae: 2.1763 - mse: 9.0945 - val_loss: 2.2143 - val_mae: 2.2143 - val_mse: 9.5851\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2069 - mae: 2.2069 - mse: 9.2530 - val_loss: 2.2522 - val_mae: 2.2522 - val_mse: 9.2398\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1994 - mae: 2.1994 - mse: 9.3300 - val_loss: 2.2859 - val_mae: 2.2859 - val_mse: 9.3585\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2520 - mae: 2.2520 - mse: 9.5733 - val_loss: 2.1363 - val_mae: 2.1363 - val_mse: 8.7774\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1667 - mae: 2.1667 - mse: 9.0899 - val_loss: 2.1638 - val_mae: 2.1638 - val_mse: 9.1163\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1782 - mae: 2.1782 - mse: 9.1466 - val_loss: 2.1308 - val_mae: 2.1308 - val_mse: 8.7968\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1796 - mae: 2.1796 - mse: 9.1732 - val_loss: 2.2105 - val_mae: 2.2105 - val_mse: 9.5225\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2028 - mae: 2.2028 - mse: 9.3063 - val_loss: 2.1258 - val_mae: 2.1258 - val_mse: 8.6937\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1791 - mae: 2.1791 - mse: 9.1942 - val_loss: 2.1388 - val_mae: 2.1388 - val_mse: 8.8941\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2120 - mae: 2.2120 - mse: 9.3927 - val_loss: 2.2734 - val_mae: 2.2734 - val_mse: 9.7525\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2006 - mae: 2.2006 - mse: 9.3498 - val_loss: 2.1914 - val_mae: 2.1914 - val_mse: 9.1225\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2031 - mae: 2.2031 - mse: 9.3378 - val_loss: 2.3306 - val_mae: 2.3306 - val_mse: 9.6962\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2016 - mae: 2.2016 - mse: 9.2518 - val_loss: 2.2079 - val_mae: 2.2079 - val_mse: 9.0128\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1861 - mae: 2.1861 - mse: 9.2130 - val_loss: 2.1416 - val_mae: 2.1416 - val_mse: 8.9143\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1998 - mae: 2.1998 - mse: 9.2880 - val_loss: 2.1865 - val_mae: 2.1865 - val_mse: 8.8995\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1817 - mae: 2.1817 - mse: 9.1683 - val_loss: 2.1240 - val_mae: 2.1240 - val_mse: 8.6838\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.1648 - mae: 2.1648 - mse: 9.0895 - val_loss: 2.2176 - val_mae: 2.2176 - val_mse: 9.2913\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.1706 - mae: 2.1706 - mse: 9.1020 - val_loss: 2.3202 - val_mae: 2.3202 - val_mse: 10.4797\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.1904 - mae: 2.1904 - mse: 9.2255 - val_loss: 2.1606 - val_mae: 2.1606 - val_mse: 8.7469\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.1737 - mae: 2.1737 - mse: 9.1846 - val_loss: 2.3366 - val_mae: 2.3366 - val_mse: 9.9342\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 2.2008 - mae: 2.2008 - mse: 9.4024 - val_loss: 2.1343 - val_mae: 2.1343 - val_mse: 8.8245\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.1913 - mae: 2.1913 - mse: 9.2601 - val_loss: 2.1511 - val_mae: 2.1511 - val_mse: 8.8389\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.1971 - mae: 2.1971 - mse: 9.2932 - val_loss: 2.1754 - val_mae: 2.1754 - val_mse: 9.2354\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2020 - mae: 2.2020 - mse: 9.3409 - val_loss: 2.1603 - val_mae: 2.1603 - val_mse: 8.7528\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2218 - mae: 2.2218 - mse: 9.3428 - val_loss: 2.1423 - val_mae: 2.1423 - val_mse: 8.8619\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1734 - mae: 2.1734 - mse: 9.1089 - val_loss: 2.3168 - val_mae: 2.3168 - val_mse: 10.4689\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.1816 - mae: 2.1816 - mse: 9.1944 - val_loss: 2.2092 - val_mae: 2.2092 - val_mse: 9.5183\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 6.5353 - mae: 6.5353 - mse: 122.4132 - val_loss: 3.7131 - val_mae: 3.7131 - val_mse: 19.4117\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.7029 - mae: 2.7029 - mse: 14.1128 - val_loss: 2.8000 - val_mae: 2.8000 - val_mse: 12.1868\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.4582 - mae: 2.4582 - mse: 12.4049 - val_loss: 2.5584 - val_mae: 2.5584 - val_mse: 10.5501\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3853 - mae: 2.3853 - mse: 11.8839 - val_loss: 2.3616 - val_mae: 2.3616 - val_mse: 9.1580\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.4247 - mae: 2.4247 - mse: 12.2894 - val_loss: 2.5006 - val_mae: 2.5006 - val_mse: 10.3125\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.4041 - mae: 2.4041 - mse: 12.0016 - val_loss: 2.2678 - val_mae: 2.2678 - val_mse: 8.5813\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3826 - mae: 2.3826 - mse: 11.8578 - val_loss: 2.4460 - val_mae: 2.4460 - val_mse: 9.6805\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3433 - mae: 2.3433 - mse: 11.6837 - val_loss: 2.4426 - val_mae: 2.4426 - val_mse: 9.7129\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3330 - mae: 2.3330 - mse: 11.6341 - val_loss: 2.5906 - val_mae: 2.5906 - val_mse: 10.7535\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3431 - mae: 2.3431 - mse: 11.7570 - val_loss: 2.1983 - val_mae: 2.1983 - val_mse: 8.3738\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3559 - mae: 2.3559 - mse: 11.7551 - val_loss: 2.2617 - val_mae: 2.2617 - val_mse: 8.9184\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3171 - mae: 2.3171 - mse: 11.4674 - val_loss: 2.2046 - val_mae: 2.2046 - val_mse: 8.4829\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3608 - mae: 2.3608 - mse: 11.7440 - val_loss: 2.3442 - val_mae: 2.3442 - val_mse: 9.5516\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3458 - mae: 2.3458 - mse: 11.7043 - val_loss: 2.4592 - val_mae: 2.4592 - val_mse: 10.3059\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3491 - mae: 2.3491 - mse: 11.6206 - val_loss: 2.3375 - val_mae: 2.3375 - val_mse: 9.4095\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3295 - mae: 2.3295 - mse: 11.5680 - val_loss: 2.2078 - val_mae: 2.2078 - val_mse: 8.3557\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3634 - mae: 2.3634 - mse: 11.7443 - val_loss: 2.2720 - val_mae: 2.2720 - val_mse: 8.9214\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3209 - mae: 2.3209 - mse: 11.5654 - val_loss: 2.2222 - val_mae: 2.2222 - val_mse: 8.5204\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3140 - mae: 2.3140 - mse: 11.5047 - val_loss: 2.2242 - val_mae: 2.2242 - val_mse: 8.6606\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3241 - mae: 2.3241 - mse: 11.5837 - val_loss: 2.2371 - val_mae: 2.2371 - val_mse: 8.4247\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3318 - mae: 2.3318 - mse: 11.4977 - val_loss: 2.2282 - val_mae: 2.2282 - val_mse: 8.3914\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3272 - mae: 2.3272 - mse: 11.5531 - val_loss: 2.2056 - val_mae: 2.2056 - val_mse: 8.4407\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3193 - mae: 2.3193 - mse: 11.5473 - val_loss: 2.2910 - val_mae: 2.2910 - val_mse: 8.8709\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3354 - mae: 2.3354 - mse: 11.5410 - val_loss: 2.2491 - val_mae: 2.2491 - val_mse: 8.7533\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3197 - mae: 2.3197 - mse: 11.5336 - val_loss: 2.2212 - val_mae: 2.2212 - val_mse: 8.6673\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3369 - mae: 2.3369 - mse: 11.6163 - val_loss: 2.2713 - val_mae: 2.2713 - val_mse: 8.6272\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3431 - mae: 2.3431 - mse: 11.5954 - val_loss: 2.2670 - val_mae: 2.2670 - val_mse: 8.5753\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3041 - mae: 2.3041 - mse: 11.3927 - val_loss: 2.3534 - val_mae: 2.3534 - val_mse: 9.0941\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3103 - mae: 2.3103 - mse: 11.4225 - val_loss: 2.2614 - val_mae: 2.2614 - val_mse: 8.8135\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3433 - mae: 2.3433 - mse: 11.6864 - val_loss: 2.2296 - val_mae: 2.2296 - val_mse: 8.6930\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3289 - mae: 2.3289 - mse: 11.5768 - val_loss: 2.2120 - val_mae: 2.2120 - val_mse: 8.3561\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 2.3240 - mae: 2.3240 - mse: 11.5417 - val_loss: 2.2958 - val_mae: 2.2958 - val_mse: 8.7409\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.3188 - mae: 2.3188 - mse: 11.5637 - val_loss: 2.3012 - val_mae: 2.3012 - val_mse: 9.0814\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3442 - mae: 2.3442 - mse: 11.6226 - val_loss: 2.2171 - val_mae: 2.2171 - val_mse: 8.6276\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3247 - mae: 2.3247 - mse: 11.5736 - val_loss: 2.3382 - val_mae: 2.3382 - val_mse: 8.9971\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3328 - mae: 2.3328 - mse: 11.5654 - val_loss: 2.2076 - val_mae: 2.2076 - val_mse: 8.4865\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3297 - mae: 2.3297 - mse: 11.6766 - val_loss: 2.3007 - val_mae: 2.3007 - val_mse: 8.7932\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3430 - mae: 2.3430 - mse: 11.6776 - val_loss: 2.2710 - val_mae: 2.2710 - val_mse: 8.6058\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3027 - mae: 2.3027 - mse: 11.3789 - val_loss: 2.2718 - val_mae: 2.2718 - val_mse: 8.6025\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3452 - mae: 2.3452 - mse: 11.5453 - val_loss: 2.2167 - val_mae: 2.2167 - val_mse: 8.5497\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3469 - mae: 2.3469 - mse: 11.6652 - val_loss: 2.2161 - val_mae: 2.2161 - val_mse: 8.3563\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3030 - mae: 2.3030 - mse: 11.4200 - val_loss: 2.2419 - val_mae: 2.2419 - val_mse: 8.8421\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3258 - mae: 2.3258 - mse: 11.6240 - val_loss: 2.2157 - val_mae: 2.2157 - val_mse: 8.3775\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3001 - mae: 2.3001 - mse: 11.4184 - val_loss: 2.2001 - val_mae: 2.2001 - val_mse: 8.3738\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3252 - mae: 2.3252 - mse: 11.5851 - val_loss: 2.2411 - val_mae: 2.2411 - val_mse: 8.5362\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3336 - mae: 2.3336 - mse: 11.5997 - val_loss: 2.1979 - val_mae: 2.1979 - val_mse: 8.3823\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3446 - mae: 2.3446 - mse: 11.7085 - val_loss: 2.2592 - val_mae: 2.2592 - val_mse: 8.5929\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.3614 - mae: 2.3614 - mse: 11.7782 - val_loss: 2.2208 - val_mae: 2.2208 - val_mse: 8.3574\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3280 - mae: 2.3280 - mse: 11.6214 - val_loss: 2.2181 - val_mae: 2.2181 - val_mse: 8.3832\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.3163 - mae: 2.3163 - mse: 11.4254 - val_loss: 2.2102 - val_mae: 2.2102 - val_mse: 8.5440\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 7s 65ms/step - loss: 9.3530 - mae: 9.3530 - mse: 282.7221 - val_loss: 6.6223 - val_mae: 6.6223 - val_mse: 64.0103\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 2s 34ms/step - loss: 2.9912 - mae: 2.9912 - mse: 16.7050 - val_loss: 3.9777 - val_mae: 3.9777 - val_mse: 27.2660\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 2s 25ms/step - loss: 2.9166 - mae: 2.9166 - mse: 16.3688 - val_loss: 4.7350 - val_mae: 4.7350 - val_mse: 35.3878\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 2.9067 - mae: 2.9067 - mse: 16.2638 - val_loss: 4.2802 - val_mae: 4.2802 - val_mse: 30.4119\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.9010 - mae: 2.9010 - mse: 16.3686 - val_loss: 2.7380 - val_mae: 2.7380 - val_mse: 16.8061\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.9618 - mae: 2.9618 - mse: 16.6650 - val_loss: 3.5854 - val_mae: 3.5854 - val_mse: 23.6772\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8087 - mae: 2.8087 - mse: 15.4517 - val_loss: 2.8323 - val_mae: 2.8323 - val_mse: 17.7141\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 2.8109 - mae: 2.8109 - mse: 15.6121 - val_loss: 2.8823 - val_mae: 2.8823 - val_mse: 18.2819\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.8733 - mae: 2.8733 - mse: 15.7535 - val_loss: 2.7707 - val_mae: 2.7707 - val_mse: 17.2629\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 1s 25ms/step - loss: 2.8725 - mae: 2.8725 - mse: 15.8730 - val_loss: 2.6962 - val_mae: 2.6962 - val_mse: 16.5687\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.8047 - mae: 2.8047 - mse: 15.4244 - val_loss: 3.0166 - val_mae: 3.0166 - val_mse: 18.8572\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.7989 - mae: 2.7989 - mse: 15.2689 - val_loss: 2.6999 - val_mae: 2.6999 - val_mse: 16.6535\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.8111 - mae: 2.8111 - mse: 15.5240 - val_loss: 2.7953 - val_mae: 2.7953 - val_mse: 17.4399\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.7766 - mae: 2.7766 - mse: 15.1675 - val_loss: 2.9108 - val_mae: 2.9108 - val_mse: 18.3696\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.8499 - mae: 2.8499 - mse: 15.7789 - val_loss: 2.7097 - val_mae: 2.7097 - val_mse: 16.7340\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 2.7924 - mae: 2.7924 - mse: 15.3032 - val_loss: 2.8524 - val_mae: 2.8524 - val_mse: 17.5171\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7944 - mae: 2.7944 - mse: 15.4116 - val_loss: 2.8385 - val_mae: 2.8385 - val_mse: 17.3926\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 2.7894 - mae: 2.7894 - mse: 15.2987 - val_loss: 2.9031 - val_mae: 2.9031 - val_mse: 18.0450\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.7705 - mae: 2.7705 - mse: 15.2477 - val_loss: 2.8471 - val_mae: 2.8471 - val_mse: 17.7309\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8094 - mae: 2.8094 - mse: 15.5505 - val_loss: 2.7415 - val_mae: 2.7415 - val_mse: 16.8221\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 2.7527 - mae: 2.7527 - mse: 15.0645 - val_loss: 2.7358 - val_mae: 2.7358 - val_mse: 16.7728\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 2.7864 - mae: 2.7864 - mse: 15.2998 - val_loss: 2.7133 - val_mae: 2.7133 - val_mse: 16.6603\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.7960 - mae: 2.7960 - mse: 15.3640 - val_loss: 2.7264 - val_mae: 2.7264 - val_mse: 16.7557\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 1s 25ms/step - loss: 2.7724 - mae: 2.7724 - mse: 15.2030 - val_loss: 2.6985 - val_mae: 2.6985 - val_mse: 16.6417\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7653 - mae: 2.7653 - mse: 15.1423 - val_loss: 2.7662 - val_mae: 2.7662 - val_mse: 17.1278\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 2s 26ms/step - loss: 2.7811 - mae: 2.7811 - mse: 15.3210 - val_loss: 2.7356 - val_mae: 2.7356 - val_mse: 16.9747\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 2s 35ms/step - loss: 2.7611 - mae: 2.7611 - mse: 15.1591 - val_loss: 2.8532 - val_mae: 2.8532 - val_mse: 17.5593\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 2s 27ms/step - loss: 2.7633 - mae: 2.7633 - mse: 15.1538 - val_loss: 2.8765 - val_mae: 2.8765 - val_mse: 17.7198\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 1s 25ms/step - loss: 2.7705 - mae: 2.7705 - mse: 15.3562 - val_loss: 2.7459 - val_mae: 2.7459 - val_mse: 17.0466\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 2.7865 - mae: 2.7865 - mse: 15.2824 - val_loss: 2.7382 - val_mae: 2.7382 - val_mse: 16.7880\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.7913 - mae: 2.7913 - mse: 15.2889 - val_loss: 2.7606 - val_mae: 2.7606 - val_mse: 17.1916\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 2s 27ms/step - loss: 2.7624 - mae: 2.7624 - mse: 15.1725 - val_loss: 3.0113 - val_mae: 3.0113 - val_mse: 18.9209\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 2s 25ms/step - loss: 2.8085 - mae: 2.8085 - mse: 15.3691 - val_loss: 2.7142 - val_mae: 2.7142 - val_mse: 16.7959\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 2s 27ms/step - loss: 2.7477 - mae: 2.7477 - mse: 15.0861 - val_loss: 2.7200 - val_mae: 2.7200 - val_mse: 16.8035\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.7918 - mae: 2.7918 - mse: 15.3515 - val_loss: 2.7754 - val_mae: 2.7754 - val_mse: 16.9983\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.7841 - mae: 2.7841 - mse: 15.2914 - val_loss: 2.8310 - val_mae: 2.8310 - val_mse: 17.5964\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 2.7532 - mae: 2.7532 - mse: 15.0635 - val_loss: 2.7904 - val_mae: 2.7904 - val_mse: 17.1352\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 2s 28ms/step - loss: 2.8085 - mae: 2.8085 - mse: 15.5025 - val_loss: 2.7562 - val_mae: 2.7562 - val_mse: 17.0148\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 2s 26ms/step - loss: 2.7543 - mae: 2.7543 - mse: 15.1271 - val_loss: 2.7282 - val_mae: 2.7282 - val_mse: 16.6605\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.7688 - mae: 2.7688 - mse: 15.1902 - val_loss: 2.7824 - val_mae: 2.7824 - val_mse: 17.2075\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.7837 - mae: 2.7837 - mse: 15.2989 - val_loss: 2.7975 - val_mae: 2.7975 - val_mse: 17.0597\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7708 - mae: 2.7708 - mse: 15.3113 - val_loss: 3.1139 - val_mae: 3.1139 - val_mse: 20.2993\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8479 - mae: 2.8479 - mse: 15.8581 - val_loss: 2.7201 - val_mae: 2.7201 - val_mse: 16.8766\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.7878 - mae: 2.7878 - mse: 15.3318 - val_loss: 2.7719 - val_mae: 2.7719 - val_mse: 17.1081\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.7732 - mae: 2.7732 - mse: 15.1682 - val_loss: 2.8680 - val_mae: 2.8680 - val_mse: 17.7090\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.7523 - mae: 2.7523 - mse: 15.0025 - val_loss: 2.8894 - val_mae: 2.8894 - val_mse: 18.3368\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.7999 - mae: 2.7999 - mse: 15.6023 - val_loss: 2.7039 - val_mae: 2.7039 - val_mse: 16.6083\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.7526 - mae: 2.7526 - mse: 15.0844 - val_loss: 2.6952 - val_mae: 2.6952 - val_mse: 16.5315\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 2.7626 - mae: 2.7626 - mse: 15.1175 - val_loss: 2.6986 - val_mae: 2.6986 - val_mse: 16.5432\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 2.7619 - mae: 2.7619 - mse: 15.1221 - val_loss: 3.0324 - val_mae: 3.0324 - val_mse: 18.9949\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 20ms/step - loss: 5.7174 - mae: 5.7174 - mse: 76.0081 - val_loss: 3.0907 - val_mae: 3.0907 - val_mse: 16.5974\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.4463 - mae: 2.4463 - mse: 11.5582 - val_loss: 2.4431 - val_mae: 2.4431 - val_mse: 11.4370\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3567 - mae: 2.3567 - mse: 10.8722 - val_loss: 2.4431 - val_mae: 2.4431 - val_mse: 11.4833\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3333 - mae: 2.3333 - mse: 10.5528 - val_loss: 2.7791 - val_mae: 2.7791 - val_mse: 14.0008\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3188 - mae: 2.3188 - mse: 10.4724 - val_loss: 2.2463 - val_mae: 2.2463 - val_mse: 10.0409\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.3105 - mae: 2.3105 - mse: 10.4720 - val_loss: 2.3345 - val_mae: 2.3345 - val_mse: 10.6442\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2869 - mae: 2.2869 - mse: 10.3989 - val_loss: 2.2944 - val_mae: 2.2944 - val_mse: 10.4035\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2736 - mae: 2.2736 - mse: 10.2350 - val_loss: 2.2557 - val_mae: 2.2557 - val_mse: 10.1566\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2851 - mae: 2.2851 - mse: 10.3349 - val_loss: 2.2711 - val_mae: 2.2711 - val_mse: 10.2640\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2917 - mae: 2.2917 - mse: 10.3482 - val_loss: 2.2379 - val_mae: 2.2379 - val_mse: 9.9900\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2590 - mae: 2.2590 - mse: 10.1662 - val_loss: 2.3290 - val_mae: 2.3290 - val_mse: 10.6413\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2985 - mae: 2.2985 - mse: 10.4220 - val_loss: 2.2297 - val_mae: 2.2297 - val_mse: 9.9392\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2964 - mae: 2.2964 - mse: 10.3843 - val_loss: 2.2368 - val_mae: 2.2368 - val_mse: 9.9676\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2846 - mae: 2.2846 - mse: 10.3564 - val_loss: 2.2717 - val_mae: 2.2717 - val_mse: 10.1737\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3029 - mae: 2.3029 - mse: 10.3716 - val_loss: 2.2481 - val_mae: 2.2481 - val_mse: 10.0327\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2661 - mae: 2.2661 - mse: 10.2706 - val_loss: 2.3243 - val_mae: 2.3243 - val_mse: 10.6371\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2844 - mae: 2.2844 - mse: 10.3535 - val_loss: 2.3518 - val_mae: 2.3518 - val_mse: 10.7572\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.3043 - mae: 2.3043 - mse: 10.4644 - val_loss: 2.2713 - val_mae: 2.2713 - val_mse: 10.2621\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2715 - mae: 2.2715 - mse: 10.2649 - val_loss: 2.2686 - val_mae: 2.2686 - val_mse: 10.1856\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2926 - mae: 2.2926 - mse: 10.3069 - val_loss: 2.2858 - val_mae: 2.2858 - val_mse: 10.3447\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2993 - mae: 2.2993 - mse: 10.3096 - val_loss: 2.2815 - val_mae: 2.2815 - val_mse: 10.3385\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2762 - mae: 2.2762 - mse: 10.2505 - val_loss: 2.3226 - val_mae: 2.3226 - val_mse: 10.5970\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.3065 - mae: 2.3065 - mse: 10.5179 - val_loss: 2.2862 - val_mae: 2.2862 - val_mse: 10.3678\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2620 - mae: 2.2620 - mse: 10.1889 - val_loss: 2.2702 - val_mae: 2.2702 - val_mse: 10.2524\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2671 - mae: 2.2671 - mse: 10.2139 - val_loss: 2.2423 - val_mae: 2.2423 - val_mse: 10.0330\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2686 - mae: 2.2686 - mse: 10.2012 - val_loss: 2.2440 - val_mae: 2.2440 - val_mse: 9.9998\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.2851 - mae: 2.2851 - mse: 10.2735 - val_loss: 2.4354 - val_mae: 2.4354 - val_mse: 11.4546\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2747 - mae: 2.2747 - mse: 10.2723 - val_loss: 2.2853 - val_mae: 2.2853 - val_mse: 10.3406\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.2709 - mae: 2.2709 - mse: 10.2307 - val_loss: 2.3096 - val_mae: 2.3096 - val_mse: 10.4999\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2642 - mae: 2.2642 - mse: 10.2135 - val_loss: 2.2343 - val_mae: 2.2343 - val_mse: 9.9362\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.2556 - mae: 2.2556 - mse: 10.1711 - val_loss: 2.2269 - val_mae: 2.2269 - val_mse: 9.9186\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.2581 - mae: 2.2581 - mse: 10.2047 - val_loss: 2.3012 - val_mae: 2.3012 - val_mse: 10.3724\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.2598 - mae: 2.2598 - mse: 10.1573 - val_loss: 2.2692 - val_mae: 2.2692 - val_mse: 10.1268\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 2.3081 - mae: 2.3081 - mse: 10.4610 - val_loss: 2.4558 - val_mae: 2.4558 - val_mse: 11.5244\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2666 - mae: 2.2666 - mse: 10.2027 - val_loss: 2.2487 - val_mae: 2.2487 - val_mse: 10.0310\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.2781 - mae: 2.2781 - mse: 10.3146 - val_loss: 2.2924 - val_mae: 2.2924 - val_mse: 10.3794\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 2.2739 - mae: 2.2739 - mse: 10.2328 - val_loss: 2.2984 - val_mae: 2.2984 - val_mse: 10.4460\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 2.2636 - mae: 2.2636 - mse: 10.2073 - val_loss: 2.2887 - val_mae: 2.2887 - val_mse: 10.2174\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.3109 - mae: 2.3109 - mse: 10.5557 - val_loss: 2.2369 - val_mae: 2.2369 - val_mse: 9.9417\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2791 - mae: 2.2791 - mse: 10.3008 - val_loss: 2.3243 - val_mae: 2.3243 - val_mse: 10.5309\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 2.2787 - mae: 2.2787 - mse: 10.2792 - val_loss: 2.3073 - val_mae: 2.3073 - val_mse: 10.5067\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2774 - mae: 2.2774 - mse: 10.2258 - val_loss: 2.3238 - val_mae: 2.3238 - val_mse: 10.4779\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 2.2663 - mae: 2.2663 - mse: 10.2333 - val_loss: 2.2265 - val_mae: 2.2265 - val_mse: 9.9010\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 2.2982 - mae: 2.2982 - mse: 10.4511 - val_loss: 2.2865 - val_mae: 2.2865 - val_mse: 10.2193\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.3078 - mae: 2.3078 - mse: 10.4843 - val_loss: 2.2362 - val_mae: 2.2362 - val_mse: 9.9523\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2809 - mae: 2.2809 - mse: 10.3271 - val_loss: 2.2370 - val_mae: 2.2370 - val_mse: 9.9542\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.2537 - mae: 2.2537 - mse: 10.1376 - val_loss: 2.2360 - val_mae: 2.2360 - val_mse: 9.9684\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2619 - mae: 2.2619 - mse: 10.1846 - val_loss: 2.3910 - val_mae: 2.3910 - val_mse: 11.0711\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2959 - mae: 2.2959 - mse: 10.3654 - val_loss: 2.3095 - val_mae: 2.3095 - val_mse: 10.4581\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.2635 - mae: 2.2635 - mse: 10.1234 - val_loss: 2.3279 - val_mae: 2.3279 - val_mse: 10.5973\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 3s 27ms/step - loss: 4.5879 - mae: 4.5879 - mse: 54.2486 - val_loss: 2.8995 - val_mae: 2.8995 - val_mse: 15.7718\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.9020 - mae: 2.9020 - mse: 14.9620 - val_loss: 3.0819 - val_mae: 3.0819 - val_mse: 17.3539\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8602 - mae: 2.8602 - mse: 14.7370 - val_loss: 3.0741 - val_mae: 3.0741 - val_mse: 17.2523\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8497 - mae: 2.8497 - mse: 14.5543 - val_loss: 2.8475 - val_mae: 2.8475 - val_mse: 15.1679\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8293 - mae: 2.8293 - mse: 14.3587 - val_loss: 2.9129 - val_mae: 2.9129 - val_mse: 15.7990\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8257 - mae: 2.8257 - mse: 14.3753 - val_loss: 2.8483 - val_mae: 2.8483 - val_mse: 15.1077\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8449 - mae: 2.8449 - mse: 14.4629 - val_loss: 2.8445 - val_mae: 2.8445 - val_mse: 15.1376\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8052 - mae: 2.8052 - mse: 14.1794 - val_loss: 2.8047 - val_mae: 2.8047 - val_mse: 14.6758\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8388 - mae: 2.8388 - mse: 14.4508 - val_loss: 3.0079 - val_mae: 3.0079 - val_mse: 16.0132\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8697 - mae: 2.8697 - mse: 14.7214 - val_loss: 3.1609 - val_mae: 3.1609 - val_mse: 17.7161\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8358 - mae: 2.8358 - mse: 14.4563 - val_loss: 2.8512 - val_mae: 2.8512 - val_mse: 14.9299\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8357 - mae: 2.8357 - mse: 14.4095 - val_loss: 2.8041 - val_mae: 2.8041 - val_mse: 14.6103\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8387 - mae: 2.8387 - mse: 14.5074 - val_loss: 2.7910 - val_mae: 2.7910 - val_mse: 14.6199\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8157 - mae: 2.8157 - mse: 14.2312 - val_loss: 2.8481 - val_mae: 2.8481 - val_mse: 14.8671\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8229 - mae: 2.8229 - mse: 14.4310 - val_loss: 2.8174 - val_mae: 2.8174 - val_mse: 14.7448\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8298 - mae: 2.8298 - mse: 14.4311 - val_loss: 2.8276 - val_mae: 2.8276 - val_mse: 14.9567\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8044 - mae: 2.8044 - mse: 14.2609 - val_loss: 2.8313 - val_mae: 2.8313 - val_mse: 14.9998\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8181 - mae: 2.8181 - mse: 14.2441 - val_loss: 2.9887 - val_mae: 2.9887 - val_mse: 16.4261\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8255 - mae: 2.8255 - mse: 14.3531 - val_loss: 2.7956 - val_mae: 2.7956 - val_mse: 14.5856\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8059 - mae: 2.8059 - mse: 14.1586 - val_loss: 2.8223 - val_mae: 2.8223 - val_mse: 14.7549\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8214 - mae: 2.8214 - mse: 14.3477 - val_loss: 2.7902 - val_mae: 2.7902 - val_mse: 14.6081\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.7999 - mae: 2.7999 - mse: 14.1549 - val_loss: 2.9083 - val_mae: 2.9083 - val_mse: 15.6522\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7967 - mae: 2.7967 - mse: 14.1890 - val_loss: 2.8161 - val_mae: 2.8161 - val_mse: 14.6906\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7879 - mae: 2.7879 - mse: 14.0804 - val_loss: 2.8623 - val_mae: 2.8623 - val_mse: 15.2155\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8024 - mae: 2.8024 - mse: 14.1433 - val_loss: 2.9209 - val_mae: 2.9209 - val_mse: 15.4756\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8148 - mae: 2.8148 - mse: 14.4041 - val_loss: 2.7867 - val_mae: 2.7867 - val_mse: 14.5666\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8033 - mae: 2.8033 - mse: 14.2232 - val_loss: 2.8245 - val_mae: 2.8245 - val_mse: 14.9058\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8222 - mae: 2.8222 - mse: 14.3212 - val_loss: 2.8598 - val_mae: 2.8598 - val_mse: 15.2788\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8476 - mae: 2.8476 - mse: 14.5101 - val_loss: 2.9620 - val_mae: 2.9620 - val_mse: 16.1944\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8217 - mae: 2.8217 - mse: 14.3570 - val_loss: 2.8422 - val_mae: 2.8422 - val_mse: 14.8202\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8262 - mae: 2.8262 - mse: 14.4077 - val_loss: 2.8015 - val_mae: 2.8015 - val_mse: 14.6081\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8058 - mae: 2.8058 - mse: 14.2501 - val_loss: 2.9347 - val_mae: 2.9347 - val_mse: 15.6132\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8334 - mae: 2.8334 - mse: 14.4836 - val_loss: 2.9202 - val_mae: 2.9202 - val_mse: 15.3300\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8830 - mae: 2.8830 - mse: 14.8448 - val_loss: 2.8502 - val_mae: 2.8502 - val_mse: 14.8969\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8106 - mae: 2.8106 - mse: 14.2382 - val_loss: 2.8423 - val_mae: 2.8423 - val_mse: 15.0169\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8047 - mae: 2.8047 - mse: 14.2148 - val_loss: 2.8311 - val_mae: 2.8311 - val_mse: 14.9897\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8157 - mae: 2.8157 - mse: 14.2558 - val_loss: 2.8509 - val_mae: 2.8509 - val_mse: 14.9255\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8129 - mae: 2.8129 - mse: 14.3784 - val_loss: 3.0090 - val_mae: 3.0090 - val_mse: 16.4728\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8426 - mae: 2.8426 - mse: 14.4943 - val_loss: 2.8421 - val_mae: 2.8421 - val_mse: 14.8884\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.7983 - mae: 2.7983 - mse: 14.1777 - val_loss: 2.9051 - val_mae: 2.9051 - val_mse: 15.3622\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8002 - mae: 2.8002 - mse: 14.1551 - val_loss: 2.7855 - val_mae: 2.7855 - val_mse: 14.5079\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8195 - mae: 2.8195 - mse: 14.3280 - val_loss: 2.7754 - val_mae: 2.7754 - val_mse: 14.4683\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7985 - mae: 2.7985 - mse: 14.1911 - val_loss: 2.8058 - val_mae: 2.8058 - val_mse: 14.5974\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8202 - mae: 2.8202 - mse: 14.3907 - val_loss: 2.8454 - val_mae: 2.8454 - val_mse: 14.8714\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 2.8412 - mae: 2.8412 - mse: 14.6047 - val_loss: 2.8352 - val_mae: 2.8352 - val_mse: 14.9522\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.8327 - mae: 2.8327 - mse: 14.4634 - val_loss: 2.8087 - val_mae: 2.8087 - val_mse: 14.6078\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 1s 16ms/step - loss: 2.7916 - mae: 2.7916 - mse: 14.2275 - val_loss: 2.8217 - val_mae: 2.8217 - val_mse: 14.6885\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 1s 17ms/step - loss: 2.8198 - mae: 2.8198 - mse: 14.3577 - val_loss: 2.7860 - val_mae: 2.7860 - val_mse: 14.4942\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.8041 - mae: 2.8041 - mse: 14.2268 - val_loss: 2.8612 - val_mae: 2.8612 - val_mse: 15.1697\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 2.8022 - mae: 2.8022 - mse: 14.1913 - val_loss: 2.8714 - val_mae: 2.8714 - val_mse: 15.0972\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 5s 18ms/step - loss: 5.7158 - mae: 5.7158 - mse: 99.4742 - val_loss: 4.1696 - val_mae: 4.1696 - val_mse: 29.3979\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.7525 - mae: 3.7525 - mse: 27.2250 - val_loss: 4.0963 - val_mae: 4.0963 - val_mse: 29.8516\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6825 - mae: 3.6825 - mse: 26.6493 - val_loss: 3.7186 - val_mae: 3.7186 - val_mse: 26.2630\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.7138 - mae: 3.7138 - mse: 26.7821 - val_loss: 3.6615 - val_mae: 3.6615 - val_mse: 25.7370\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 3.6880 - mae: 3.6880 - mse: 26.5668 - val_loss: 3.6514 - val_mae: 3.6514 - val_mse: 25.9954\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6835 - mae: 3.6835 - mse: 26.5900 - val_loss: 3.5749 - val_mae: 3.5749 - val_mse: 26.2396\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6532 - mae: 3.6532 - mse: 26.2376 - val_loss: 3.7182 - val_mae: 3.7182 - val_mse: 26.6331\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6598 - mae: 3.6598 - mse: 26.3527 - val_loss: 3.6399 - val_mae: 3.6399 - val_mse: 25.5640\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6581 - mae: 3.6581 - mse: 26.3773 - val_loss: 3.6178 - val_mae: 3.6178 - val_mse: 25.4202\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6516 - mae: 3.6516 - mse: 26.2399 - val_loss: 3.6210 - val_mae: 3.6210 - val_mse: 25.4339\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6501 - mae: 3.6501 - mse: 26.3131 - val_loss: 3.6327 - val_mae: 3.6327 - val_mse: 25.7691\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6454 - mae: 3.6454 - mse: 26.0649 - val_loss: 3.5832 - val_mae: 3.5832 - val_mse: 25.6865\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6508 - mae: 3.6508 - mse: 26.1903 - val_loss: 3.6379 - val_mae: 3.6379 - val_mse: 25.5389\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6433 - mae: 3.6433 - mse: 26.1656 - val_loss: 3.5719 - val_mae: 3.5719 - val_mse: 25.2290\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6519 - mae: 3.6519 - mse: 26.2509 - val_loss: 3.7657 - val_mae: 3.7657 - val_mse: 26.7155\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6539 - mae: 3.6539 - mse: 26.2242 - val_loss: 3.5873 - val_mae: 3.5873 - val_mse: 25.4813\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6326 - mae: 3.6326 - mse: 26.0214 - val_loss: 3.6692 - val_mae: 3.6692 - val_mse: 25.8673\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6447 - mae: 3.6447 - mse: 26.0206 - val_loss: 3.6117 - val_mae: 3.6117 - val_mse: 25.3825\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6376 - mae: 3.6376 - mse: 26.0759 - val_loss: 3.5737 - val_mae: 3.5737 - val_mse: 25.6775\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6441 - mae: 3.6441 - mse: 26.1558 - val_loss: 3.5791 - val_mae: 3.5791 - val_mse: 25.1537\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6249 - mae: 3.6249 - mse: 25.9071 - val_loss: 3.5402 - val_mae: 3.5402 - val_mse: 25.2667\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6112 - mae: 3.6112 - mse: 25.7199 - val_loss: 3.5993 - val_mae: 3.5993 - val_mse: 25.3515\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6281 - mae: 3.6281 - mse: 25.8842 - val_loss: 3.5394 - val_mae: 3.5394 - val_mse: 25.5740\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6195 - mae: 3.6195 - mse: 25.8137 - val_loss: 3.5582 - val_mae: 3.5582 - val_mse: 25.4442\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6100 - mae: 3.6100 - mse: 25.6086 - val_loss: 3.5662 - val_mae: 3.5662 - val_mse: 25.0554\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6301 - mae: 3.6301 - mse: 25.7768 - val_loss: 3.6524 - val_mae: 3.6524 - val_mse: 27.9945\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6072 - mae: 3.6072 - mse: 25.5759 - val_loss: 3.5367 - val_mae: 3.5367 - val_mse: 25.4501\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 3.6007 - mae: 3.6007 - mse: 25.4931 - val_loss: 3.6001 - val_mae: 3.6001 - val_mse: 25.2500\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6070 - mae: 3.6070 - mse: 25.5302 - val_loss: 3.5658 - val_mae: 3.5658 - val_mse: 25.2578\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6109 - mae: 3.6109 - mse: 25.6163 - val_loss: 3.5297 - val_mae: 3.5297 - val_mse: 25.3690\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6195 - mae: 3.6195 - mse: 25.6699 - val_loss: 3.6735 - val_mae: 3.6735 - val_mse: 25.8922\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6011 - mae: 3.6011 - mse: 25.4245 - val_loss: 3.5358 - val_mae: 3.5358 - val_mse: 25.0396\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.5884 - mae: 3.5884 - mse: 25.3915 - val_loss: 3.5343 - val_mae: 3.5343 - val_mse: 24.7828\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.5961 - mae: 3.5961 - mse: 25.3940 - val_loss: 3.5450 - val_mae: 3.5450 - val_mse: 25.4972\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6066 - mae: 3.6066 - mse: 25.5074 - val_loss: 3.5198 - val_mae: 3.5198 - val_mse: 24.8868\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.5865 - mae: 3.5865 - mse: 25.3984 - val_loss: 3.5278 - val_mae: 3.5278 - val_mse: 24.6729\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.5911 - mae: 3.5911 - mse: 25.2675 - val_loss: 3.5523 - val_mae: 3.5523 - val_mse: 25.2519\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.5942 - mae: 3.5942 - mse: 25.3910 - val_loss: 3.5233 - val_mae: 3.5233 - val_mse: 25.4645\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.5989 - mae: 3.5989 - mse: 25.3888 - val_loss: 3.5166 - val_mae: 3.5166 - val_mse: 24.9215\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.5930 - mae: 3.5930 - mse: 25.2744 - val_loss: 3.5956 - val_mae: 3.5956 - val_mse: 25.9422\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.6022 - mae: 3.6022 - mse: 25.2822 - val_loss: 3.5288 - val_mae: 3.5288 - val_mse: 24.6997\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.5876 - mae: 3.5876 - mse: 25.2469 - val_loss: 3.5470 - val_mae: 3.5470 - val_mse: 25.3909\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.6096 - mae: 3.6096 - mse: 25.4923 - val_loss: 3.5176 - val_mae: 3.5176 - val_mse: 24.7717\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.5952 - mae: 3.5952 - mse: 25.3415 - val_loss: 3.5557 - val_mae: 3.5557 - val_mse: 25.4037\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.6062 - mae: 3.6062 - mse: 25.3878 - val_loss: 3.5611 - val_mae: 3.5611 - val_mse: 25.0276\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.5866 - mae: 3.5866 - mse: 25.1968 - val_loss: 3.6219 - val_mae: 3.6219 - val_mse: 27.3237\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 3.5698 - mae: 3.5698 - mse: 25.1299 - val_loss: 3.5695 - val_mae: 3.5695 - val_mse: 25.4788\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.5889 - mae: 3.5889 - mse: 25.3044 - val_loss: 3.5572 - val_mae: 3.5572 - val_mse: 24.7276\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 3.5950 - mae: 3.5950 - mse: 25.2911 - val_loss: 3.5371 - val_mae: 3.5371 - val_mse: 25.3789\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 3.5656 - mae: 3.5656 - mse: 24.9376 - val_loss: 3.6715 - val_mae: 3.6715 - val_mse: 28.0974\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 9.8299 - mae: 9.8299 - mse: 281.9743 - val_loss: 7.8272 - val_mae: 7.8272 - val_mse: 78.8105\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.5764 - mae: 3.5764 - mse: 22.6351 - val_loss: 6.5532 - val_mae: 6.5532 - val_mse: 62.2286\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5286 - mae: 3.5286 - mse: 21.9024 - val_loss: 6.0668 - val_mae: 6.0668 - val_mse: 50.9113\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5615 - mae: 3.5615 - mse: 22.5600 - val_loss: 4.1901 - val_mae: 4.1901 - val_mse: 28.1568\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3788 - mae: 3.3788 - mse: 20.3850 - val_loss: 3.7792 - val_mae: 3.7792 - val_mse: 23.8055\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3824 - mae: 3.3824 - mse: 20.5290 - val_loss: 4.0774 - val_mae: 4.0774 - val_mse: 28.5872\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.4243 - mae: 3.4243 - mse: 20.8684 - val_loss: 4.5281 - val_mae: 4.5281 - val_mse: 31.4925\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3790 - mae: 3.3790 - mse: 20.6437 - val_loss: 3.3952 - val_mae: 3.3952 - val_mse: 19.7242\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.3698 - mae: 3.3698 - mse: 20.3014 - val_loss: 3.5303 - val_mae: 3.5303 - val_mse: 20.9873\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.3978 - mae: 3.3978 - mse: 20.6040 - val_loss: 3.2785 - val_mae: 3.2785 - val_mse: 18.4561\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.4570 - mae: 3.4570 - mse: 21.0194 - val_loss: 3.2481 - val_mae: 3.2481 - val_mse: 18.0075\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.3543 - mae: 3.3543 - mse: 20.2723 - val_loss: 3.3865 - val_mae: 3.3865 - val_mse: 19.7357\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.3067 - mae: 3.3067 - mse: 19.7724 - val_loss: 3.3837 - val_mae: 3.3837 - val_mse: 18.8862\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3327 - mae: 3.3327 - mse: 19.8537 - val_loss: 3.3336 - val_mae: 3.3336 - val_mse: 18.7685\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2819 - mae: 3.2819 - mse: 19.6035 - val_loss: 3.3391 - val_mae: 3.3391 - val_mse: 18.9912\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4358 - mae: 3.4358 - mse: 20.8749 - val_loss: 3.4555 - val_mae: 3.4555 - val_mse: 19.6966\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2896 - mae: 3.2896 - mse: 19.6021 - val_loss: 3.2803 - val_mae: 3.2803 - val_mse: 18.2351\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3420 - mae: 3.3420 - mse: 19.9228 - val_loss: 3.4669 - val_mae: 3.4669 - val_mse: 20.2085\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3899 - mae: 3.3899 - mse: 20.4008 - val_loss: 3.4880 - val_mae: 3.4880 - val_mse: 20.7045\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2772 - mae: 3.2772 - mse: 19.3859 - val_loss: 3.2880 - val_mae: 3.2880 - val_mse: 18.4744\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2940 - mae: 3.2940 - mse: 19.6119 - val_loss: 3.3805 - val_mae: 3.3805 - val_mse: 19.2967\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3053 - mae: 3.3053 - mse: 19.7085 - val_loss: 3.2606 - val_mae: 3.2606 - val_mse: 18.1854\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2947 - mae: 3.2947 - mse: 19.5517 - val_loss: 3.2892 - val_mae: 3.2892 - val_mse: 18.5453\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2876 - mae: 3.2876 - mse: 19.5610 - val_loss: 3.2803 - val_mae: 3.2803 - val_mse: 18.3666\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2951 - mae: 3.2951 - mse: 19.5977 - val_loss: 3.3721 - val_mae: 3.3721 - val_mse: 19.2318\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2991 - mae: 3.2991 - mse: 19.6363 - val_loss: 3.4545 - val_mae: 3.4545 - val_mse: 19.8247\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.3521 - mae: 3.3521 - mse: 20.2146 - val_loss: 3.2473 - val_mae: 3.2473 - val_mse: 17.8978\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2925 - mae: 3.2925 - mse: 19.6463 - val_loss: 3.3063 - val_mae: 3.3063 - val_mse: 18.6954\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.3161 - mae: 3.3161 - mse: 20.0583 - val_loss: 3.2549 - val_mae: 3.2549 - val_mse: 17.8522\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3165 - mae: 3.3165 - mse: 19.6527 - val_loss: 3.2635 - val_mae: 3.2635 - val_mse: 18.2924\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2640 - mae: 3.2640 - mse: 19.3423 - val_loss: 3.3913 - val_mae: 3.3913 - val_mse: 19.7943\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2730 - mae: 3.2730 - mse: 19.4795 - val_loss: 3.2604 - val_mae: 3.2604 - val_mse: 17.9541\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2570 - mae: 3.2570 - mse: 19.3352 - val_loss: 3.2997 - val_mae: 3.2997 - val_mse: 18.5231\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2659 - mae: 3.2659 - mse: 19.3328 - val_loss: 3.2507 - val_mae: 3.2507 - val_mse: 18.0847\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3170 - mae: 3.3170 - mse: 19.8949 - val_loss: 3.2561 - val_mae: 3.2561 - val_mse: 17.8938\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2806 - mae: 3.2806 - mse: 19.4317 - val_loss: 3.3205 - val_mae: 3.3205 - val_mse: 18.7625\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2821 - mae: 3.2821 - mse: 19.3948 - val_loss: 3.2833 - val_mae: 3.2833 - val_mse: 18.3897\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2841 - mae: 3.2841 - mse: 19.3855 - val_loss: 3.2630 - val_mae: 3.2630 - val_mse: 18.2309\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2788 - mae: 3.2788 - mse: 19.3692 - val_loss: 3.3019 - val_mae: 3.3019 - val_mse: 18.5454\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2866 - mae: 3.2866 - mse: 19.4734 - val_loss: 3.2653 - val_mae: 3.2653 - val_mse: 17.9047\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2765 - mae: 3.2765 - mse: 19.4081 - val_loss: 3.3179 - val_mae: 3.3179 - val_mse: 18.6412\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2805 - mae: 3.2805 - mse: 19.3782 - val_loss: 3.2920 - val_mae: 3.2920 - val_mse: 18.4312\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2650 - mae: 3.2650 - mse: 19.5096 - val_loss: 3.2581 - val_mae: 3.2581 - val_mse: 18.0494\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2968 - mae: 3.2968 - mse: 19.7441 - val_loss: 3.3140 - val_mae: 3.3140 - val_mse: 18.4538\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2943 - mae: 3.2943 - mse: 19.5816 - val_loss: 3.3785 - val_mae: 3.3785 - val_mse: 19.2687\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2750 - mae: 3.2750 - mse: 19.4758 - val_loss: 3.3685 - val_mae: 3.3685 - val_mse: 18.8688\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2827 - mae: 3.2827 - mse: 19.4425 - val_loss: 3.2851 - val_mae: 3.2851 - val_mse: 18.0163\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2567 - mae: 3.2567 - mse: 19.2609 - val_loss: 3.2838 - val_mae: 3.2838 - val_mse: 18.1720\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3247 - mae: 3.3247 - mse: 20.1797 - val_loss: 3.2991 - val_mae: 3.2991 - val_mse: 18.7818\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2806 - mae: 3.2806 - mse: 19.4751 - val_loss: 3.2841 - val_mae: 3.2841 - val_mse: 18.3833\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 2s 20ms/step - loss: 7.8417 - mae: 7.8417 - mse: 174.8273 - val_loss: 6.7054 - val_mae: 6.7054 - val_mse: 62.0487\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.4232 - mae: 3.4232 - mse: 20.3407 - val_loss: 5.1920 - val_mae: 5.1920 - val_mse: 41.3692\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.4232 - mae: 3.4232 - mse: 20.2992 - val_loss: 4.4449 - val_mae: 4.4449 - val_mse: 35.2549\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4956 - mae: 3.4956 - mse: 20.9015 - val_loss: 3.5825 - val_mae: 3.5825 - val_mse: 24.2831\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2859 - mae: 3.2859 - mse: 18.6231 - val_loss: 4.8499 - val_mae: 4.8499 - val_mse: 37.8716\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3537 - mae: 3.3537 - mse: 19.4231 - val_loss: 3.7376 - val_mae: 3.7376 - val_mse: 25.9278\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2773 - mae: 3.2773 - mse: 18.4739 - val_loss: 3.3575 - val_mae: 3.3575 - val_mse: 21.5473\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2475 - mae: 3.2475 - mse: 18.6509 - val_loss: 3.3181 - val_mae: 3.3181 - val_mse: 21.2419\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2367 - mae: 3.2367 - mse: 18.1256 - val_loss: 3.4903 - val_mae: 3.4903 - val_mse: 23.0460\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2337 - mae: 3.2337 - mse: 18.2415 - val_loss: 3.4360 - val_mae: 3.4360 - val_mse: 22.3549\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2411 - mae: 3.2411 - mse: 18.1929 - val_loss: 3.2032 - val_mae: 3.2032 - val_mse: 19.8093\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2194 - mae: 3.2194 - mse: 18.0506 - val_loss: 3.1876 - val_mae: 3.1876 - val_mse: 19.1328\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2675 - mae: 3.2675 - mse: 18.5451 - val_loss: 3.1716 - val_mae: 3.1716 - val_mse: 19.1944\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2315 - mae: 3.2315 - mse: 18.1774 - val_loss: 3.3061 - val_mae: 3.3061 - val_mse: 20.9885\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1998 - mae: 3.1998 - mse: 17.9944 - val_loss: 3.2266 - val_mae: 3.2266 - val_mse: 20.1519\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2861 - mae: 3.2861 - mse: 18.8509 - val_loss: 3.2423 - val_mae: 3.2423 - val_mse: 20.1071\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2139 - mae: 3.2139 - mse: 17.9118 - val_loss: 3.1910 - val_mae: 3.1910 - val_mse: 19.6562\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2093 - mae: 3.2093 - mse: 18.0571 - val_loss: 3.2631 - val_mae: 3.2631 - val_mse: 20.6340\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1943 - mae: 3.1943 - mse: 17.7316 - val_loss: 3.1894 - val_mae: 3.1894 - val_mse: 19.6420\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1835 - mae: 3.1835 - mse: 17.7526 - val_loss: 3.1668 - val_mae: 3.1668 - val_mse: 19.1349\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2885 - mae: 3.2885 - mse: 18.9741 - val_loss: 3.3612 - val_mae: 3.3612 - val_mse: 21.3452\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2300 - mae: 3.2300 - mse: 18.1220 - val_loss: 3.2759 - val_mae: 3.2759 - val_mse: 20.6826\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2072 - mae: 3.2072 - mse: 17.9097 - val_loss: 3.2258 - val_mae: 3.2258 - val_mse: 19.4486\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1922 - mae: 3.1922 - mse: 17.7886 - val_loss: 3.3066 - val_mae: 3.3066 - val_mse: 20.7290\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2092 - mae: 3.2092 - mse: 18.0410 - val_loss: 3.1736 - val_mae: 3.1736 - val_mse: 19.4243\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2046 - mae: 3.2046 - mse: 17.9097 - val_loss: 3.7274 - val_mae: 3.7274 - val_mse: 25.2676\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2539 - mae: 3.2539 - mse: 18.3451 - val_loss: 3.1730 - val_mae: 3.1730 - val_mse: 19.4068\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 3.2319 - mae: 3.2319 - mse: 18.3639 - val_loss: 3.1884 - val_mae: 3.1884 - val_mse: 19.4787\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.1865 - mae: 3.1865 - mse: 17.8244 - val_loss: 3.3289 - val_mae: 3.3289 - val_mse: 21.4228\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1863 - mae: 3.1863 - mse: 17.8227 - val_loss: 3.1702 - val_mae: 3.1702 - val_mse: 19.0950\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1773 - mae: 3.1773 - mse: 17.7250 - val_loss: 3.2676 - val_mae: 3.2676 - val_mse: 20.4544\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2143 - mae: 3.2143 - mse: 18.0425 - val_loss: 3.1934 - val_mae: 3.1934 - val_mse: 19.5528\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1953 - mae: 3.1953 - mse: 17.7855 - val_loss: 3.2614 - val_mae: 3.2614 - val_mse: 19.4883\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1977 - mae: 3.1977 - mse: 17.7646 - val_loss: 3.1636 - val_mae: 3.1636 - val_mse: 19.1081\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1854 - mae: 3.1854 - mse: 17.8199 - val_loss: 3.1844 - val_mae: 3.1844 - val_mse: 19.4547\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1598 - mae: 3.1598 - mse: 17.5382 - val_loss: 3.2292 - val_mae: 3.2292 - val_mse: 19.9214\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1871 - mae: 3.1871 - mse: 17.6696 - val_loss: 3.2519 - val_mae: 3.2519 - val_mse: 20.3345\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2166 - mae: 3.2166 - mse: 18.1674 - val_loss: 3.2195 - val_mae: 3.2195 - val_mse: 20.0651\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2181 - mae: 3.2181 - mse: 18.1312 - val_loss: 3.1934 - val_mae: 3.1934 - val_mse: 19.7173\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2095 - mae: 3.2095 - mse: 18.0442 - val_loss: 3.2278 - val_mae: 3.2278 - val_mse: 19.4862\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2772 - mae: 3.2772 - mse: 18.6612 - val_loss: 3.2958 - val_mae: 3.2958 - val_mse: 20.5981\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2125 - mae: 3.2125 - mse: 17.9832 - val_loss: 3.1722 - val_mae: 3.1722 - val_mse: 19.0928\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1559 - mae: 3.1559 - mse: 17.5507 - val_loss: 3.1683 - val_mae: 3.1683 - val_mse: 19.2322\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1651 - mae: 3.1651 - mse: 17.5538 - val_loss: 3.1756 - val_mae: 3.1756 - val_mse: 19.4974\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2013 - mae: 3.2013 - mse: 17.9802 - val_loss: 3.1730 - val_mae: 3.1730 - val_mse: 19.2995\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2133 - mae: 3.2133 - mse: 17.9531 - val_loss: 3.1997 - val_mae: 3.1997 - val_mse: 19.7400\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1586 - mae: 3.1586 - mse: 17.5014 - val_loss: 3.1834 - val_mae: 3.1834 - val_mse: 19.3707\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1742 - mae: 3.1742 - mse: 17.7049 - val_loss: 3.3571 - val_mae: 3.3571 - val_mse: 20.7085\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2109 - mae: 3.2109 - mse: 18.0814 - val_loss: 3.1956 - val_mae: 3.1956 - val_mse: 19.4266\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1840 - mae: 3.1840 - mse: 17.7365 - val_loss: 3.1790 - val_mae: 3.1790 - val_mse: 19.5417\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 3s 25ms/step - loss: 8.7296 - mae: 8.7296 - mse: 223.4238 - val_loss: 7.6862 - val_mae: 7.6862 - val_mse: 79.8093\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.4454 - mae: 3.4454 - mse: 21.8784 - val_loss: 6.1612 - val_mae: 6.1612 - val_mse: 58.6855\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3442 - mae: 3.3442 - mse: 20.9887 - val_loss: 5.7560 - val_mae: 5.7560 - val_mse: 47.5412\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3951 - mae: 3.3951 - mse: 21.7444 - val_loss: 5.7922 - val_mae: 5.7922 - val_mse: 56.5003\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.4950 - mae: 3.4950 - mse: 22.4405 - val_loss: 3.9139 - val_mae: 3.9139 - val_mse: 28.1166\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2502 - mae: 3.2502 - mse: 20.2165 - val_loss: 3.1981 - val_mae: 3.1981 - val_mse: 21.2620\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2402 - mae: 3.2402 - mse: 20.2174 - val_loss: 3.6244 - val_mae: 3.6244 - val_mse: 24.9501\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.2101 - mae: 3.2101 - mse: 19.8844 - val_loss: 3.3204 - val_mae: 3.3204 - val_mse: 22.4608\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2189 - mae: 3.2189 - mse: 19.9821 - val_loss: 4.0797 - val_mae: 4.0797 - val_mse: 29.6589\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 3.1563 - mae: 3.1563 - mse: 19.3063 - val_loss: 3.8574 - val_mae: 3.8574 - val_mse: 29.2598\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2130 - mae: 3.2130 - mse: 20.1323 - val_loss: 3.8958 - val_mae: 3.8958 - val_mse: 30.0599\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1720 - mae: 3.1720 - mse: 19.6287 - val_loss: 3.6745 - val_mae: 3.6745 - val_mse: 26.7621\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1674 - mae: 3.1674 - mse: 19.4153 - val_loss: 3.2636 - val_mae: 3.2636 - val_mse: 21.5309\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1693 - mae: 3.1693 - mse: 19.3939 - val_loss: 3.7565 - val_mae: 3.7565 - val_mse: 25.5290\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1687 - mae: 3.1687 - mse: 19.4309 - val_loss: 3.3479 - val_mae: 3.3479 - val_mse: 22.7741\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1470 - mae: 3.1470 - mse: 19.3866 - val_loss: 3.6577 - val_mae: 3.6577 - val_mse: 26.7913\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1734 - mae: 3.1734 - mse: 19.7136 - val_loss: 3.4190 - val_mae: 3.4190 - val_mse: 23.3423\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1881 - mae: 3.1881 - mse: 19.7509 - val_loss: 3.3955 - val_mae: 3.3955 - val_mse: 23.2626\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1218 - mae: 3.1218 - mse: 19.1637 - val_loss: 3.1748 - val_mae: 3.1748 - val_mse: 21.0127\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2087 - mae: 3.2087 - mse: 19.4183 - val_loss: 3.4996 - val_mae: 3.4996 - val_mse: 24.3639\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1779 - mae: 3.1779 - mse: 19.4713 - val_loss: 3.1693 - val_mae: 3.1693 - val_mse: 20.8909\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1636 - mae: 3.1636 - mse: 19.3494 - val_loss: 3.1967 - val_mae: 3.1967 - val_mse: 21.2267\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1581 - mae: 3.1581 - mse: 19.3148 - val_loss: 3.5309 - val_mae: 3.5309 - val_mse: 24.7431\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1890 - mae: 3.1890 - mse: 19.5913 - val_loss: 3.3163 - val_mae: 3.3163 - val_mse: 21.9503\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.1569 - mae: 3.1569 - mse: 19.4065 - val_loss: 3.1869 - val_mae: 3.1869 - val_mse: 21.1163\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 3.1707 - mae: 3.1707 - mse: 19.3780 - val_loss: 3.6477 - val_mae: 3.6477 - val_mse: 26.1379\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1957 - mae: 3.1957 - mse: 19.7414 - val_loss: 3.1433 - val_mae: 3.1433 - val_mse: 20.8020\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1503 - mae: 3.1503 - mse: 19.4467 - val_loss: 3.1578 - val_mae: 3.1578 - val_mse: 20.8861\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1459 - mae: 3.1459 - mse: 19.3938 - val_loss: 3.3382 - val_mae: 3.3382 - val_mse: 22.5235\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1423 - mae: 3.1423 - mse: 19.2093 - val_loss: 3.1749 - val_mae: 3.1749 - val_mse: 20.9624\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1432 - mae: 3.1432 - mse: 19.5901 - val_loss: 3.1417 - val_mae: 3.1417 - val_mse: 20.7697\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1694 - mae: 3.1694 - mse: 19.4310 - val_loss: 3.3125 - val_mae: 3.3125 - val_mse: 22.3138\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1249 - mae: 3.1249 - mse: 19.0506 - val_loss: 3.3294 - val_mae: 3.3294 - val_mse: 22.4887\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1076 - mae: 3.1076 - mse: 18.8782 - val_loss: 3.2773 - val_mae: 3.2773 - val_mse: 21.9237\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1052 - mae: 3.1052 - mse: 18.9750 - val_loss: 3.2825 - val_mae: 3.2825 - val_mse: 21.9146\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1419 - mae: 3.1419 - mse: 19.3793 - val_loss: 3.0987 - val_mae: 3.0987 - val_mse: 20.4946\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1674 - mae: 3.1674 - mse: 19.4735 - val_loss: 3.3253 - val_mae: 3.3253 - val_mse: 22.2943\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1598 - mae: 3.1598 - mse: 19.3513 - val_loss: 3.2734 - val_mae: 3.2734 - val_mse: 21.7818\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1777 - mae: 3.1777 - mse: 19.5412 - val_loss: 3.1719 - val_mae: 3.1719 - val_mse: 20.9507\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1646 - mae: 3.1646 - mse: 19.3823 - val_loss: 3.2256 - val_mae: 3.2256 - val_mse: 21.4175\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1078 - mae: 3.1078 - mse: 18.8945 - val_loss: 3.1483 - val_mae: 3.1483 - val_mse: 20.7723\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1126 - mae: 3.1126 - mse: 18.7598 - val_loss: 3.1885 - val_mae: 3.1885 - val_mse: 20.9854\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 3.1238 - mae: 3.1238 - mse: 18.9584 - val_loss: 3.3319 - val_mae: 3.3319 - val_mse: 22.4098\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1476 - mae: 3.1476 - mse: 19.1738 - val_loss: 3.1608 - val_mae: 3.1608 - val_mse: 21.0630\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.1469 - mae: 3.1469 - mse: 19.0371 - val_loss: 3.2266 - val_mae: 3.2266 - val_mse: 21.3903\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1242 - mae: 3.1242 - mse: 18.8812 - val_loss: 3.4379 - val_mae: 3.4379 - val_mse: 23.8399\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.0934 - mae: 3.0934 - mse: 18.7094 - val_loss: 3.3182 - val_mae: 3.3182 - val_mse: 22.1713\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1212 - mae: 3.1212 - mse: 18.7195 - val_loss: 3.3817 - val_mae: 3.3817 - val_mse: 22.2113\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.0821 - mae: 3.0821 - mse: 18.5455 - val_loss: 3.1142 - val_mae: 3.1142 - val_mse: 20.4677\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1132 - mae: 3.1132 - mse: 18.8444 - val_loss: 3.2379 - val_mae: 3.2379 - val_mse: 21.5196\n",
            "Epoch 1/50\n",
            "187/187 [==============================] - 5s 19ms/step - loss: 5.8693 - mae: 5.8693 - mse: 108.2448 - val_loss: 5.0456 - val_mae: 5.0456 - val_mse: 45.8957\n",
            "Epoch 2/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.7321 - mae: 3.7321 - mse: 25.9758 - val_loss: 3.6378 - val_mae: 3.6378 - val_mse: 25.0615\n",
            "Epoch 3/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.6366 - mae: 3.6366 - mse: 24.8940 - val_loss: 3.9196 - val_mae: 3.9196 - val_mse: 29.1290\n",
            "Epoch 4/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 3.6082 - mae: 3.6082 - mse: 24.5246 - val_loss: 3.7054 - val_mae: 3.7054 - val_mse: 26.1314\n",
            "Epoch 5/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 3.5885 - mae: 3.5885 - mse: 24.4743 - val_loss: 3.7874 - val_mae: 3.7874 - val_mse: 26.4290\n",
            "Epoch 6/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.6093 - mae: 3.6093 - mse: 24.6840 - val_loss: 3.5432 - val_mae: 3.5432 - val_mse: 23.3902\n",
            "Epoch 7/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.6065 - mae: 3.6065 - mse: 24.5232 - val_loss: 3.9126 - val_mae: 3.9126 - val_mse: 29.1709\n",
            "Epoch 8/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5944 - mae: 3.5944 - mse: 24.3504 - val_loss: 3.6278 - val_mae: 3.6278 - val_mse: 24.9397\n",
            "Epoch 9/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5590 - mae: 3.5590 - mse: 24.1589 - val_loss: 3.5703 - val_mae: 3.5703 - val_mse: 23.4617\n",
            "Epoch 10/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5548 - mae: 3.5548 - mse: 24.1072 - val_loss: 3.5444 - val_mae: 3.5444 - val_mse: 23.3334\n",
            "Epoch 11/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5588 - mae: 3.5588 - mse: 24.1104 - val_loss: 3.5782 - val_mae: 3.5782 - val_mse: 24.4190\n",
            "Epoch 12/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5430 - mae: 3.5430 - mse: 23.9551 - val_loss: 3.6251 - val_mae: 3.6251 - val_mse: 24.5022\n",
            "Epoch 13/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5849 - mae: 3.5849 - mse: 24.4296 - val_loss: 3.5310 - val_mae: 3.5310 - val_mse: 23.3573\n",
            "Epoch 14/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5318 - mae: 3.5318 - mse: 23.8140 - val_loss: 3.6307 - val_mae: 3.6307 - val_mse: 25.2334\n",
            "Epoch 15/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5340 - mae: 3.5340 - mse: 23.8681 - val_loss: 3.6458 - val_mae: 3.6458 - val_mse: 25.2348\n",
            "Epoch 16/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 3.5416 - mae: 3.5416 - mse: 23.8588 - val_loss: 3.6139 - val_mae: 3.6139 - val_mse: 24.3934\n",
            "Epoch 17/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5448 - mae: 3.5448 - mse: 24.0128 - val_loss: 3.7379 - val_mae: 3.7379 - val_mse: 25.1845\n",
            "Epoch 18/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5376 - mae: 3.5376 - mse: 23.8251 - val_loss: 3.6388 - val_mae: 3.6388 - val_mse: 24.4449\n",
            "Epoch 19/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5469 - mae: 3.5469 - mse: 24.0936 - val_loss: 3.5719 - val_mae: 3.5719 - val_mse: 24.3655\n",
            "Epoch 20/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5376 - mae: 3.5376 - mse: 23.9041 - val_loss: 3.5419 - val_mae: 3.5419 - val_mse: 23.3844\n",
            "Epoch 21/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5265 - mae: 3.5265 - mse: 23.7506 - val_loss: 3.5369 - val_mae: 3.5369 - val_mse: 23.7280\n",
            "Epoch 22/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5258 - mae: 3.5258 - mse: 23.7153 - val_loss: 3.5239 - val_mae: 3.5239 - val_mse: 23.2059\n",
            "Epoch 23/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5372 - mae: 3.5372 - mse: 23.9233 - val_loss: 3.5515 - val_mae: 3.5515 - val_mse: 24.0378\n",
            "Epoch 24/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5296 - mae: 3.5296 - mse: 23.7980 - val_loss: 3.5165 - val_mae: 3.5165 - val_mse: 23.2371\n",
            "Epoch 25/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5239 - mae: 3.5239 - mse: 23.8217 - val_loss: 3.5858 - val_mae: 3.5858 - val_mse: 24.1764\n",
            "Epoch 26/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5586 - mae: 3.5586 - mse: 24.0747 - val_loss: 3.5655 - val_mae: 3.5655 - val_mse: 24.2375\n",
            "Epoch 27/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5639 - mae: 3.5639 - mse: 24.1745 - val_loss: 3.5601 - val_mae: 3.5601 - val_mse: 23.3490\n",
            "Epoch 28/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5258 - mae: 3.5258 - mse: 23.7289 - val_loss: 3.5609 - val_mae: 3.5609 - val_mse: 23.8961\n",
            "Epoch 29/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5198 - mae: 3.5198 - mse: 23.7135 - val_loss: 3.6230 - val_mae: 3.6230 - val_mse: 25.2327\n",
            "Epoch 30/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5256 - mae: 3.5256 - mse: 23.7727 - val_loss: 3.5664 - val_mae: 3.5664 - val_mse: 23.6814\n",
            "Epoch 31/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5230 - mae: 3.5230 - mse: 23.7801 - val_loss: 3.5427 - val_mae: 3.5427 - val_mse: 23.2070\n",
            "Epoch 32/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5358 - mae: 3.5358 - mse: 23.8404 - val_loss: 3.7785 - val_mae: 3.7785 - val_mse: 27.2872\n",
            "Epoch 33/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5423 - mae: 3.5423 - mse: 23.9106 - val_loss: 3.6567 - val_mae: 3.6567 - val_mse: 25.5515\n",
            "Epoch 34/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5187 - mae: 3.5187 - mse: 23.7083 - val_loss: 3.5385 - val_mae: 3.5385 - val_mse: 23.3857\n",
            "Epoch 35/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5270 - mae: 3.5270 - mse: 23.7790 - val_loss: 3.5685 - val_mae: 3.5685 - val_mse: 24.3657\n",
            "Epoch 36/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5072 - mae: 3.5072 - mse: 23.6203 - val_loss: 3.5535 - val_mae: 3.5535 - val_mse: 24.0611\n",
            "Epoch 37/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5116 - mae: 3.5116 - mse: 23.6091 - val_loss: 3.5746 - val_mae: 3.5746 - val_mse: 23.4331\n",
            "Epoch 38/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5136 - mae: 3.5136 - mse: 23.7064 - val_loss: 3.5270 - val_mae: 3.5270 - val_mse: 23.5023\n",
            "Epoch 39/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5283 - mae: 3.5283 - mse: 23.7974 - val_loss: 3.5351 - val_mae: 3.5351 - val_mse: 23.4212\n",
            "Epoch 40/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5273 - mae: 3.5273 - mse: 23.7136 - val_loss: 3.5389 - val_mae: 3.5389 - val_mse: 23.4072\n",
            "Epoch 41/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5324 - mae: 3.5324 - mse: 23.7704 - val_loss: 3.6086 - val_mae: 3.6086 - val_mse: 24.9938\n",
            "Epoch 42/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5295 - mae: 3.5295 - mse: 23.7339 - val_loss: 3.5099 - val_mae: 3.5099 - val_mse: 23.2958\n",
            "Epoch 43/50\n",
            "187/187 [==============================] - 3s 17ms/step - loss: 3.5244 - mae: 3.5244 - mse: 23.6583 - val_loss: 3.6195 - val_mae: 3.6195 - val_mse: 23.7738\n",
            "Epoch 44/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 3.5148 - mae: 3.5148 - mse: 23.6794 - val_loss: 3.6107 - val_mae: 3.6107 - val_mse: 23.8818\n",
            "Epoch 45/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5134 - mae: 3.5134 - mse: 23.6747 - val_loss: 3.5703 - val_mae: 3.5703 - val_mse: 23.3651\n",
            "Epoch 46/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5127 - mae: 3.5127 - mse: 23.6780 - val_loss: 3.5140 - val_mae: 3.5140 - val_mse: 23.1843\n",
            "Epoch 47/50\n",
            "187/187 [==============================] - 3s 15ms/step - loss: 3.5195 - mae: 3.5195 - mse: 23.7340 - val_loss: 3.5160 - val_mae: 3.5160 - val_mse: 23.1277\n",
            "Epoch 48/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5095 - mae: 3.5095 - mse: 23.5782 - val_loss: 3.5208 - val_mae: 3.5208 - val_mse: 23.4921\n",
            "Epoch 49/50\n",
            "187/187 [==============================] - 3s 18ms/step - loss: 3.5003 - mae: 3.5003 - mse: 23.5160 - val_loss: 3.5184 - val_mae: 3.5184 - val_mse: 23.0238\n",
            "Epoch 50/50\n",
            "187/187 [==============================] - 3s 16ms/step - loss: 3.5161 - mae: 3.5161 - mse: 23.6389 - val_loss: 3.5185 - val_mae: 3.5185 - val_mse: 23.0650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean Absolute Error is:{np.array(val_mae).mean()}\")\n",
        "print(f\"Mean Square Error is:{np.array(val_mse).mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MI5oJbECxO5",
        "outputId": "fa5baae2-2467-4362-8cd3-6bb40ee9dc35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error is:2.6395238240559897\n",
            "Mean Square Error is:14.592045497894286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_paths =sorted(glob.glob('/content/images/test_images/*'))"
      ],
      "metadata": {
        "id": "Fah6bTPlDE02"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "for i in test_image_paths:\n",
        "  tim = tf.image.rgb_to_grayscale(tf.convert_to_tensor(Image.open(i),dtype = tf.float32))/255.\n",
        "  test_images.append(tim)\n",
        "\n",
        "test_images = np.array(test_images)"
      ],
      "metadata": {
        "id": "y6F5mch8DiWl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0  = tf.keras.models.load_model(model_names[0])\n",
        "model_1  = tf.keras.models.load_model(model_names[1])\n",
        "model_2  = tf.keras.models.load_model(model_names[2])\n",
        "model_3  = tf.keras.models.load_model(model_names[3])\n",
        "model_4  = tf.keras.models.load_model(model_names[4])\n",
        "model_5  = tf.keras.models.load_model(model_names[5])\n",
        "model_6  = tf.keras.models.load_model(model_names[6])\n",
        "model_7  = tf.keras.models.load_model(model_names[7])\n",
        "model_8  = tf.keras.models.load_model(model_names[8])\n",
        "model_9  = tf.keras.models.load_model(model_names[9])\n",
        "model_10 = tf.keras.models.load_model(model_names[10])\n",
        "model_11 = tf.keras.models.load_model(model_names[11])\n",
        "model_12 = tf.keras.models.load_model(model_names[12])\n",
        "model_13 = tf.keras.models.load_model(model_names[13])\n",
        "model_14 = tf.keras.models.load_model(model_names[14])"
      ],
      "metadata": {
        "id": "X1io4-1hFINa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  p_0 = model_0.predict(test_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8SyePuHsRo",
        "outputId": "15dac5dd-3a63-4514-aa1c-afeedfd6450e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx9jyNJMIVGU",
        "outputId": "234f32b1-51f5-4d61-c84d-52d7b5449308"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1783, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_0 = model_0.predict(test_images)\n",
        "p_1 = model_1.predict(test_images)\n",
        "p_2 = model_2.predict(test_images)\n",
        "p_3 = model_3.predict(test_images)\n",
        "p_4 = model_4.predict(test_images)\n",
        "p_5 = model_5.predict(test_images)\n",
        "p_6 = model_6.predict(test_images)\n",
        "p_7 = model_7.predict(test_images)\n",
        "p_8 = model_8.predict(test_images)\n",
        "p_9 = model_9.predict(test_images)\n",
        "p_10 = model_10.predict(test_images)\n",
        "p_11 = model_11.predict(test_images)\n",
        "p_12 = model_12.predict(test_images)\n",
        "p_13 = model_13.predict(test_images)\n",
        "p_14 = model_14.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_8c_LjFGBUA",
        "outputId": "629af42f-b43d-4056-b727-bbfb86197a6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 0s 6ms/step\n",
            "56/56 [==============================] - 0s 5ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "56/56 [==============================] - 0s 5ms/step\n",
            "56/56 [==============================] - 1s 5ms/step\n",
            "56/56 [==============================] - 0s 4ms/step\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "56/56 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame(np.concatenate([p_0, p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_10, p_11, p_12, p_13, p_14], axis=1), columns=df.columns[:-1])"
      ],
      "metadata": {
        "id": "XAI66m3dIKTv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "rIyg2YITJfIv",
        "outputId": "97ae9eeb-c287-4e59-e190-264d922153df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
              "0          66.976776          37.499985           30.636349   \n",
              "1          66.976852          37.501701           30.590332   \n",
              "2          66.975975          37.500080           30.621872   \n",
              "3          66.977768          37.500824           30.650740   \n",
              "4          66.975510          37.501846           30.664541   \n",
              "\n",
              "   right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
              "0           37.207886                58.174217                38.372700   \n",
              "1           37.121853                58.035263                38.450348   \n",
              "2           37.162369                58.185944                38.397369   \n",
              "3           37.216408                57.872498                38.427959   \n",
              "4           37.233524                57.863632                38.477707   \n",
              "\n",
              "   left_eye_outer_corner_x  left_eye_outer_corner_y  right_eye_inner_corner_x  \\\n",
              "0                71.602539                37.667965                 37.063866   \n",
              "1                71.838837                37.765568                 37.203106   \n",
              "2                71.649269                37.682262                 37.037743   \n",
              "3                71.599174                37.559975                 37.585449   \n",
              "4                71.727287                37.707352                 37.466961   \n",
              "\n",
              "   right_eye_inner_corner_y  ...  nose_tip_x  nose_tip_y  mouth_left_corner_x  \\\n",
              "0                 38.911293  ...   48.585442   65.272964            62.908424   \n",
              "1                 38.875874  ...   48.495102   65.080162            62.844635   \n",
              "2                 38.891800  ...   48.546295   64.949760            62.881130   \n",
              "3                 39.369560  ...   48.810646   66.245224            62.969387   \n",
              "4                 39.126194  ...   48.837982   66.447525            62.931290   \n",
              "\n",
              "   mouth_left_corner_y  mouth_right_corner_x  mouth_right_corner_y  \\\n",
              "0            75.035744             33.377647             75.514488   \n",
              "1            75.029617             33.372414             75.541695   \n",
              "2            75.026352             33.360271             75.542770   \n",
              "3            75.085052             33.207882             75.526749   \n",
              "4            75.071892             33.306099             75.515045   \n",
              "\n",
              "   mouth_center_top_lip_x  mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
              "0               47.662361               71.412613                  48.982029   \n",
              "1               47.743290               71.712097                  48.919434   \n",
              "2               47.736614               71.574059                  48.932888   \n",
              "3               47.700275               71.365662                  48.951107   \n",
              "4               47.746708               71.675858                  49.093292   \n",
              "\n",
              "   mouth_center_bottom_lip_y  \n",
              "0                  79.738159  \n",
              "1                  79.219360  \n",
              "2                  79.691803  \n",
              "3                  78.577271  \n",
              "4                  78.262169  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a0fd9eb-0cdd-4eeb-93bd-125df5788c99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>left_eye_center_x</th>\n",
              "      <th>left_eye_center_y</th>\n",
              "      <th>right_eye_center_x</th>\n",
              "      <th>right_eye_center_y</th>\n",
              "      <th>left_eye_inner_corner_x</th>\n",
              "      <th>left_eye_inner_corner_y</th>\n",
              "      <th>left_eye_outer_corner_x</th>\n",
              "      <th>left_eye_outer_corner_y</th>\n",
              "      <th>right_eye_inner_corner_x</th>\n",
              "      <th>right_eye_inner_corner_y</th>\n",
              "      <th>...</th>\n",
              "      <th>nose_tip_x</th>\n",
              "      <th>nose_tip_y</th>\n",
              "      <th>mouth_left_corner_x</th>\n",
              "      <th>mouth_left_corner_y</th>\n",
              "      <th>mouth_right_corner_x</th>\n",
              "      <th>mouth_right_corner_y</th>\n",
              "      <th>mouth_center_top_lip_x</th>\n",
              "      <th>mouth_center_top_lip_y</th>\n",
              "      <th>mouth_center_bottom_lip_x</th>\n",
              "      <th>mouth_center_bottom_lip_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66.976776</td>\n",
              "      <td>37.499985</td>\n",
              "      <td>30.636349</td>\n",
              "      <td>37.207886</td>\n",
              "      <td>58.174217</td>\n",
              "      <td>38.372700</td>\n",
              "      <td>71.602539</td>\n",
              "      <td>37.667965</td>\n",
              "      <td>37.063866</td>\n",
              "      <td>38.911293</td>\n",
              "      <td>...</td>\n",
              "      <td>48.585442</td>\n",
              "      <td>65.272964</td>\n",
              "      <td>62.908424</td>\n",
              "      <td>75.035744</td>\n",
              "      <td>33.377647</td>\n",
              "      <td>75.514488</td>\n",
              "      <td>47.662361</td>\n",
              "      <td>71.412613</td>\n",
              "      <td>48.982029</td>\n",
              "      <td>79.738159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>66.976852</td>\n",
              "      <td>37.501701</td>\n",
              "      <td>30.590332</td>\n",
              "      <td>37.121853</td>\n",
              "      <td>58.035263</td>\n",
              "      <td>38.450348</td>\n",
              "      <td>71.838837</td>\n",
              "      <td>37.765568</td>\n",
              "      <td>37.203106</td>\n",
              "      <td>38.875874</td>\n",
              "      <td>...</td>\n",
              "      <td>48.495102</td>\n",
              "      <td>65.080162</td>\n",
              "      <td>62.844635</td>\n",
              "      <td>75.029617</td>\n",
              "      <td>33.372414</td>\n",
              "      <td>75.541695</td>\n",
              "      <td>47.743290</td>\n",
              "      <td>71.712097</td>\n",
              "      <td>48.919434</td>\n",
              "      <td>79.219360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66.975975</td>\n",
              "      <td>37.500080</td>\n",
              "      <td>30.621872</td>\n",
              "      <td>37.162369</td>\n",
              "      <td>58.185944</td>\n",
              "      <td>38.397369</td>\n",
              "      <td>71.649269</td>\n",
              "      <td>37.682262</td>\n",
              "      <td>37.037743</td>\n",
              "      <td>38.891800</td>\n",
              "      <td>...</td>\n",
              "      <td>48.546295</td>\n",
              "      <td>64.949760</td>\n",
              "      <td>62.881130</td>\n",
              "      <td>75.026352</td>\n",
              "      <td>33.360271</td>\n",
              "      <td>75.542770</td>\n",
              "      <td>47.736614</td>\n",
              "      <td>71.574059</td>\n",
              "      <td>48.932888</td>\n",
              "      <td>79.691803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66.977768</td>\n",
              "      <td>37.500824</td>\n",
              "      <td>30.650740</td>\n",
              "      <td>37.216408</td>\n",
              "      <td>57.872498</td>\n",
              "      <td>38.427959</td>\n",
              "      <td>71.599174</td>\n",
              "      <td>37.559975</td>\n",
              "      <td>37.585449</td>\n",
              "      <td>39.369560</td>\n",
              "      <td>...</td>\n",
              "      <td>48.810646</td>\n",
              "      <td>66.245224</td>\n",
              "      <td>62.969387</td>\n",
              "      <td>75.085052</td>\n",
              "      <td>33.207882</td>\n",
              "      <td>75.526749</td>\n",
              "      <td>47.700275</td>\n",
              "      <td>71.365662</td>\n",
              "      <td>48.951107</td>\n",
              "      <td>78.577271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66.975510</td>\n",
              "      <td>37.501846</td>\n",
              "      <td>30.664541</td>\n",
              "      <td>37.233524</td>\n",
              "      <td>57.863632</td>\n",
              "      <td>38.477707</td>\n",
              "      <td>71.727287</td>\n",
              "      <td>37.707352</td>\n",
              "      <td>37.466961</td>\n",
              "      <td>39.126194</td>\n",
              "      <td>...</td>\n",
              "      <td>48.837982</td>\n",
              "      <td>66.447525</td>\n",
              "      <td>62.931290</td>\n",
              "      <td>75.071892</td>\n",
              "      <td>33.306099</td>\n",
              "      <td>75.515045</td>\n",
              "      <td>47.746708</td>\n",
              "      <td>71.675858</td>\n",
              "      <td>49.093292</td>\n",
              "      <td>78.262169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a0fd9eb-0cdd-4eeb-93bd-125df5788c99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a0fd9eb-0cdd-4eeb-93bd-125df5788c99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a0fd9eb-0cdd-4eeb-93bd-125df5788c99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69b55ffa-061d-4473-abcc-4fa98bb7fb8d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69b55ffa-061d-4473-abcc-4fa98bb7fb8d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69b55ffa-061d-4473-abcc-4fa98bb7fb8d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGNo = random.randint(0,len(test_images)-1)\n",
        "print(f\"Test Image Number : {IMGNo}\")\n",
        "testImage = img.imread(test_image_paths[IMGNo])\n",
        "plt.imshow(testImage,cmap='gray')\n",
        "plt.plot(predictions.iloc[IMGNo,::2],predictions.iloc[IMGNo,1::2],'bo', markersize=2);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "BFQUkrosJkfq",
        "outputId": "2e0ca68b-06ea-4113-d078-c49023896379"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Image Number : 391\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcq0lEQVR4nO29e3RW5Zn3fyUgJwkBEvIkIQkExIaDVDmKUKdWRqZjZ3Sknem77Aw9rOm0hVZk3qp0qn21VWzn92sZu6hO++tYu0bH1lnTw9hV+3No1WqRQxAVgQAFJBKScArhJGKy3z8su9f9zZP7ys1+4n4C389arpWLfbr3ve/93O7re1/XVRBFUSSEEELIu0xh2g0ghBByYcIJiBBCSCpwAiKEEJIKnIAIIYSkAicgQgghqcAJiBBCSCpwAiKEEJIKnIAIIYSkAicgQgghqcAJiBBCSCr02gS0atUqGTt2rAwaNEhmz54t69at661LEUII6YMU9EYuuB/96Efyd3/3d/LQQw/J7NmzZeXKlfLEE09IQ0ODlJWVeY/t7OyUpqYmKSoqkoKCglw3jRBCSC8TRZEcO3ZMKisrpbDQ850T9QKzZs2KFi9eHNsdHR1RZWVltGLFCvPYxsbGSET4H//jf/yP//Xx/xobG72/9/0lx7z11ltSX18vy5cvj/+tsLBQ5s+fL2vWrOmy/+nTp+X06dOxHf3hg2zBggVy0UUXiYjI22+/7RyDtv5SGjBggLPt7Dm6w3cuEZHt27c7dqQ+GDs7O51tJ0+edOyBAwd6z43/Z3Do0CHHHj16dPz3pEmTnG3V1dWO3b+/+yg7Ojoc+9SpU47d3t4e/92vXz/xge1EG+8r5MsV241twedntSWknXitCJwBobYPvHbIsaEk9RzotiW5Z+vcCL5Puewj7JMRI0Y4dm1trWNPnDjRscePH+89/49+9KP471WrVjnb8L0eNGiQY+O7iuO2tLTUsYuLi+O/KysrnW11dXWOje3GfsD36+KLL3Zs/X5iO8+cOSPdceLECVm4cKEUFRV1u4+ISM4noIMHD0pHR4dkMhnn3zOZjGzbtq3L/itWrJC77767y79fdNFFcedYP3Daxg61JiDr3L4fKWtCSWrra+PEipObNQHhy63Pl+YEhM+nNycgX/+KvLsTED6PJCTp/2zotp2vExBOAkOGDHHsoUOHOvawYcO859fH47gKHXe4Hd9t/U7g74J1X9gPeDxOQPpa+D/rvgmou+shOZ+AQlm+fLksW7Ysttvb26W6uloGDhwY3/xbb73lHIM37uskPBYHAz4A/FLwTTLWj7xl40AbPHiwY5eXl8d/o3aG++K5sY+wX/S1QyeU0AnJB75clo195mur1W588ZP8kIf+WIZOEr7/8cn1BKSPz/UEhO+M776QJNfG9wPf84MHDzr2nj17HBt/2PGrZOzYsfHf1157rbPtP//zPx0b30Uc4zgJ4H0fP348/vvEiRPdbhPpep/WubU3SsR936xxpu/D+h//+Jge7RVAaWmp9OvXT1paWpx/b2lpcX5QzzJw4MAu/zdPCCHk/Cfny7AHDBgg06dPl9WrV8f/1tnZKatXr5Y5c+bk+nKEEEL6KL3iglu2bJksWrRIZsyYIbNmzZKVK1fKiRMn5BOf+ERvXI4QQkgfpFcmoL/5m7+RAwcOyF133SXNzc1y+eWXy1NPPdVlYYKPt99+O/YxWsK0xhLZ0AeNK9eOHDni2G+++aZjaz8nbkPfLrbT0oRQ+NQr3VADQt8taj7WihXdNksLCV08EaJJJNWAkBANCPvI2t93H6FaSZLtllaSVBN6Nxch+FaV5hLrfcH3HrHGnX4/586d62x77rnnHPvAgQOOjc8HdRrcrset9XuGGpBeQSfSdYyjZq61r95YSNNrixCWLFkiS5Ys6a3TE0II6eMwFxwhhJBU4ARECCEkFVKPA+qOkydPxjoF6jjoj9Vr13FJN0biHj161LFbW1sd+9ixY46N6+r1tVEDsnzvVtaFiooKx9Z+ZYz7aWtrc2wriA9tX+yUpYVYgXYh2knSc4XEAeU6cNgXL2M9jzQDUa2sDPkSBxQ6pn2glmi9m/g70Nzc7Nio1+rfHYwZeu973+vYL774ovdaeF/47uvzY0YHvE8rDhLfP9TG9DOwNFTdh9if3cEvIEIIIanACYgQQkgq5K0LbtSoUbHrTSfOFPGny8FPSvwERZcaLlu0Ep9qdx9+roYsnxTp+rlcU1Pj2PrzGj9/8dqhrpGQZb65TM3jS98hYufBCnHvhbqmQl2NGmspe65dWb5rhdq+tiXNh2c9b98y7Fz2IV4Xr4XvJqakwd8gdN1rtxi6+adPn+7Ye/fudezNmzc7Nv5GoZutqqoq/huTkaK7Dn//UDZAd6HvN8t6P3Sf9tTFzC8gQgghqcAJiBBCSCpwAiKEEJIKeasBvfe97439mZs2bXK24RJk7fdEXy/6YzF9OS7TtopDaU3IKu2AoM8al3JiUSytKaFP1UqhgdfyLaG0dBXL9xuylNpKlRR67lxqQLkua+A7l1UaIsm5e7tcQ5Jz+WrhYJ9YqatC+gyvi9ouvvdooy6DmpBuG55bF5YUERkzZoxj796927HxNwrvW/9mDR8+3NmG7xP+LmBxPEzNg2EsWgvDPkT9SF/LW4ZbwS8gQgghqcAJiBBCSCpwAiKEEJIKeasBlZaWxvXMMUUNpq7Qa9tx/T76iVEjsuqc+9azW/qEFfczatQox8b1/r5ro68X79u6tk8DCtV8QnSbXKfD8WFpH1aKfSSXsTy51GWSxjshvVmOwad9WXFASeKCLO3Q0ptQS8FYRK2H4LuGsTcYu4N2Y2OjY6MmpK+N7cI4ICwJg2UnrHddXwv3xd8r/dvZ0/HMLyBCCCGpwAmIEEJIKnACIoQQkgp5qwEdPXo09m/iWvWRI0c69o4dO+K/UdMZNmyYY+M6dyyPi7nhUFvR+EqDZ2sL+oZLS0sdG/2m2neM17JyW6EdEn8RmhMtiQZklSlIEi9j5Wez/NS9WULB0mF6syS31ad6e2/msEt6viQakDVmrWuhVuwrP3D48GHHxt8kXXZFRKSpqcmxUQPScZCoh2Nco1XGBfUpvA/9e4i/nYivVHh38AuIEEJIKnACIoQQkgqcgAghhKRC3mpAjz/+eKxzzJgxw9mGPlHtx8TYGvRpvvHGG46NGg9qQLjOXudvQ78xHot+Y1w3j7ngUGM4Gwcl0tWnij5o1ITwvtDWcQtJc71ZObr0/iG53LJtt9qir+0r/2y1M5uN6PNbMSxWjBji06+S1GMSsUuw++prWe1MUi8oVKuyNDnfWLDigKw6Rng+HS+DOdJwX4zhQy0Y8dVDwxx1lu6JbcHfUtSjtN6O50Y9KTSuToRfQIQQQlKCExAhhJBU4ARECCEkFfJWA6qpqYljX9BnjTV+9HYrtxuue7dyI/n86aG5qkLjTpLsmyS3mOVrt66dy3xtoW3RtnUs+qxDn49PA0J6syaPr13ZrmXdt69t1rNPEjeUVE8KIWkNJXze+nfHyieJ7wfG7mCcEP5GHTx4sNtjMa8cXhvHBo4FjDfUehb2AWpd+r58cVHOMT3aixBCCMkxnIAIIYSkAicgQgghqZC3GlBbW1vsj8S16uhjxfgaDa6ht+rmYL6jkLiVUD8yXtunbyTVZXzaiqVHhOZAw/11DEWo5mP1UQiWphDaD9oO1YCs7SG6jBXDEtoW31gKfT5WrFVIO0L1Jx9J61Ih+r6tOCuMKRo+fLhjY1zQoUOHHLulpSX+++KLL3a2YVyQpf+h5oP3iW3VhOiv3cEvIEIIIanACYgQQkgq5K0LbsiQIfHnIX6CIrpcg+UKwfQ3+ImKqXdClqSGphJBVyLavmW+lh3iwglxi4iEp7QJcSVa17K253J5c8i5krpfk1wbsfrUGuMhY94ah7i/z6UTSi5LolvpqLDdIUv40c2F+6IbDSUFvLZO+WWlDtPpvLJdC0vd+NqKzxZ/r/S+uK07+AVECCEkFTgBEUIISQVOQIQQQlIhbzWg973vfXE52d/+9rfOtl27djm29j2izxM1H/SRoq/S8o9rv3Po8lfcH6+FS8R129DfjUs9LU3Bp/OELo22jvctXcdtVsqO0OXmvnaF6iohuo6l94WWB08zVY8v3ZR1botcljVP0kfW8mTUXVAb8dnWUmdMB4b7o06DKW90n2M78XnocgrZzo0lu7FUhB7XOG7Q9pVd6Q5+ARFCCEkFTkCEEEJSgRMQIYSQVMhbDSiKotifaek62odqpR+3UofkMjV9aBwQ+oZ9a+l9MUPZSOIvt+7D2l/bofEwSUo8W/uibz40tkrfl6VV4Xa8NhKSDifXJCk5YtkhGlAuy52E6JTZtofYuA2ftS6pnW1/TAfmK3tglf/G+8LfUryWL42Q9Tz073BPy3PzC4gQQkgqcAIihBCSCpyACCGEpELeakD19fXxmnTMd4Rr132xORhbgzoL+pHRd5mkHIN1LPprfXFAeKwVBxRSdtm3nj+bnbScsSZUzwjNW+cjNI9ZLq+NJCk/HRpDlCTmKFTjCdGAksZp+TQh632wnm3IfYdqplbckC9/Hl4LfyuPHTvm2BgXZOnSvmvlQovkFxAhhJBU4ARECCEkFTgBEUIISYW81YBOnToV6xyYMw39mtpvWVRU5GzDdfLoT02if4TGDlg+btR1tI3nwnaH5mvznQsJvQ8kpFRvb+ZIs/LpheYpC4l7CK17FKIJhWp0Fr7nFVoPCO1c6mgh99XTuJSzJLlvS49FQmsN+Wr0WLGEoTq1bgvu63u2PX02/AIihBCSCpyACCGEpAInIEIIIamQtxpQYWFht/5i9C/qGhboT0UfqJWTy/JZa58o5lHCHE94LqzF0dbW5thWXicN3if6fq370PoH3oeFFbfg8xWH5FfLZiM+bcTSQqxzh8TTWDoaguPSN85we2j8hVX7xnefSfLjZbOx7XocY7usOkYhbcFjfbE1Il11Z1+ONBG37VaOOozVwfcH24r523S8IJ4Lx5U1zrAf8DdK9zGeC2sH6d8gjGnsDn4BEUIISQVOQIQQQlKBExAhhJBUyFsN6Pjx47F/0hcfI+L6NXGblQsOfb1WfqkQX78VS4D+WJ/f2WqXdW1Enw99u+iTtq7tyx8lElYrJTTmyJd7LGlMUcj+SeKTRMK0LyvfGmLFsPi0kxC9KNu5rfpcvnaGxqyE1GtKUlso2/6+XHBWHBC+95Zu7ct9ib9vx48f914LdRwfrAdECCHkvIETECGEkFTIWxfcmTNnunUt4NJBbVspa6xPcavMgbaxHaHpO/B4n/si1M0SUqLbWqKa1C3pWyaf5jJsa2ltLtMAWSQp+2GNacRyBftcplY7sU+tcicavA/c1yqVEjIWrO3WuPO5FkPfVQzfwD7E+9bvkBV2cuLECce2xoovjZDVJ75x0+0xPdqLEEIIyTGcgAghhKQCJyBCCCGpkLcakE7FE5IyHLE0HTw3+lB9GpIvrUi27ZYG5EsPEqovhWgrlqZjpfOwnocvTbtvSb2IrRn5fPtJy2MkKVVtLZW29IxcLsNOsvw8VKOzNFif5hCiTWU7l28cW6l3EEtfCtGArKXpVtqawYMHO7YvfREus8Zl2dgPVioyX4qh0PIl2eAXECGEkFTgBEQIISQVgiagFStWyMyZM6WoqEjKysrkxhtvlIaGBmefN998UxYvXiwlJSUydOhQWbhwobS0tOS00YQQQvo+QY7RZ599VhYvXiwzZ86Ut99+W770pS/JddddJ1u2bInTeN96663yi1/8Qp544gkpLi6WJUuWyE033SQvvPBCUMMKCgpiH2+Ifx01BUxFgenLfWUKsuFLO4NpLawS0JYO4EuFbpVbsHQZ7Qu2NAVsN/qN0cZ+0NfOpe4i4k+hYulmVhqSkHgaK+VMqEbn0zWtsgWhuk1IuhxrXKHdm6l4rLb5CL2WNZZ892XpYFY6MJ9Og/vi7117e3u37RKx71OfP0Tf6+mzCJqAnnrqKcf+wQ9+IGVlZVJfXy9XX321HD16VL7//e/LY489Jh/4wAdEROThhx+WiRMnyosvvihXXnllyOUIIYScxyTSgI4ePSoiIiNHjhQRkfr6ejlz5ozMnz8/3qeurk5qampkzZo1Wc9x+vRpaW9vd/4jhBBy/nPOE1BnZ6csXbpU5s6dK1OmTBERkebmZhkwYIAMHz7c2TeTyUhzc3PW86xYsUKKi4vj/6qrq8+1SYQQQvoQ5xwHtHjxYtm8ebM8//zziRqwfPlyWbZsWWy3t7dLdXW1EwdkaRTa34j7on6BWgr6rC2dJiQOyIopsnyq2jdsaTxWWQOf/zw0P5tVktt3PuwzLAdu6WIWIeUYrD4NiTux8phZsSBWH4foG9Z94/Px5W8Ljc2xtJWelmrOdmxoKXJfDIt1rSRlJ6xnb2lAlg6tfyew/zH32+HDh73Xwrbhbxa+nxprbPSEc5qAlixZIk8++aQ899xzUlVVFf97eXm5vPXWW9LW1uZ8BbW0tEh5eXnWcw0cONB7k4QQQs5PgqasKIpkyZIl8pOf/ER+/etfS21trbN9+vTpctFFF8nq1avjf2toaJC9e/fKnDlzctNiQggh5wVBX0CLFy+Wxx57TH72s59JUVFRrOsUFxfL4MGDpbi4WD71qU/JsmXLZOTIkTJs2DD5/Oc/L3PmzOEKOEIIIQ5BE9CDDz4oIiLvf//7nX9/+OGH5eMf/7iIiHzrW9+SwsJCWbhwoZw+fVoWLFgg3/nOd3LS2LNYZZ01lr6BWL58ny/Z0pMs364v/gbvA2NYcLtPTxJxfb2+GiAiXfvXKnvu86fjNsxz5YtXEgkry2zpFdgnVkyLT5cJ1ZOscebzp4dqIUly4IVqI1YMmU8PsfQk1CdCdJ1QrcqyQ/KgWTFh+P5YfaaxNFSsNRQa7+TD0jF7QtAE1JPGDRo0SFatWiWrVq0KbgwhhJALB+aCI4QQkgqcgAghhKRC3tYD0n7QkDggS/OxzmWt2fdt8+XvynYtxOdDterkWPoT5sDT8QLHjh1ztg0aNMix0c9sxS/54p2w3WdzCHa33co756uphPuGajzWta3n7cPStny++dB6QKG1ijShmgE+exyHvvNZ4ypUU9XnwzFt5XZLmpNQY2lAVrwgoschvj9Dhw51bOxT1I59eRvxeOs+tN1TjYxfQIQQQlKBExAhhJBUyFsXXL9+/eLPQfz0833246cffqIWFRU59pEjRxwb3U2Y2kJ/sqIbBffFT+vQpdT6UxvPhS4CXG6J7iKsyaTdF9hu7G9M8Y77o3uvpKTEsfV9vvrqq842dBmUlpZ6bXQpYDC0fn579uxxto0YMcKxLTcmjhVfmicrlY615Bv7DJ+3Pt5y4eC4wrahyzVkKbvl0sYS0DgufeMQ+2TIkCGOjfcVkt4I76OsrMyx8b3H+8D7RpeebrvlUrOeHz4fHIdNTU3d7jtt2jTHrqurc2y8L3x38b70u26583xpsLqDX0CEEEJSgRMQIYSQVOAERAghJBXyVgPq7OzsdimfTwNCPzJqQMOGDXNs9L+ivpGtXd2B/lPrWCs9i/aj4n2gz/rAgQOOvW/fPsc+Wzww27UxUzmmx6moqHBs7P/GxkbvtbTOhufGdPG4tBY1BNQFUDvRfXjo0CFvu3AsWOUysO36GVjLxy39b8eOHY6Nups+n6XxWNuxD/Ed0H3uW74v4n/WIrbepPvQWuZubUd9Q/ch1ihDLepsUc2zTJ482bFHjx7t2Hv37nXs/fv3x39XVlY626xl76gPWuUZdD/4+lNEZNSoUY6NYx7HiqU1+/CV8egOfgERQghJBU5AhBBCUoETECGEkFTIWw2oo6Mj9j9aqdG17x79xBhngj5OtNH3jmh/LPpqEcv3a6Vj0fujVmL53tEXvHDhQsfW/nPUUaZMmeLY06dPd+z169c79kMPPeTY27Ztc2zddiv+Av36qEGgroOp7LVPG/386O/GPkWdrbi42LFRBxgzZkz8N44769njudHPj9t1v+AYbW9vd2wrvX9NTY33WrrKMepeOO62bt3q2Lt27fLamUzGsfH91KD+h88Px61Pd2tra/O2A8fhG2+84dhWnJc+HnUy1NwQ1K7w+aHtSwGF21DbwudplT0PiQk7F/gFRAghJBU4ARFCCEkFTkCEEEJSIW81IF856pDyuOjbxVgdKx05bte6D/pm0WeN+hL6uzE3GfpftR+6tbXV2Yb3ZZ173rx5jq395c8884yzDbWT3bt3O/YLL7zg2Ni2Sy65xLF1jBI+S9TRrBgV1CBwuwbzyKE/HLUQ1BBQW8H71PdSXV3tbMN4Cxx3qDFgP6Aepftw586dzjarT9B3jzFHOG71uLZijHAcoj1x4kTHxvvU8Tl4bl+7stl43/o3BMcVjmnUwVAHxeeJ96F1nJCSLiJ2qXG8lt4fj0U9Cd83bJsVc+TTgHIBv4AIIYSkAicgQgghqcAJiBBCSCrkrQak44AsDUjbVqldaz3/2LFjHdun82BsAfpT8dpWqWvUGHSONWz3pEmTHBs1A8xVtXHjxm7bhv2r81qJdI2XWbt2rWNjvi/UVrRGgT5q9GGjDoNxC3if6LPWPm70++O5MI4E929ubnbshoYGx9b59vDc+OwPHjzo2JYWiWNcH49jEvUnvA+sJ4PPC2Ot9Di2ynljW3x6hUhXHU73A/YJ6jI4NjCWB9+JCRMmxH/X19c723AM47uHOhneJ+qcWm/E2CfUZy0NG+8Tr62fFz47fL+sfJOIr2S61W7mgiOEENJn4ARECCEkFTgBEUIISYW81YA0Vh0dnwaEGgEei/5Z9CNjXiftc8VYAqzBg9dGG3UazOemY3nQj4++dcyRZtXd0ZoC+pzxntH3i/eBNUcwfkPrAliXBWNYrHpAlh6otRS8FoLXxn5AjQg1B92H+DxwzGJMEdYewvtAv78eKxiTghoQ6jCoNWIuOd87g+8L9j9qqFa9GbT1tfHZo76B27HdOoediPsMpk2b5mzD9+mll15y7HXr1jk2akL4vE6d+lPZsiUjkya1SHm5qx36cjyK+Ov9iHQdO/r5WfFjeC7E0sw1OKZzoQH1iQmIkCQ0Nl4hzc0Tpbx8q1RXv2QfQEgA27fXyY9/fLUUFnbKL3/5Hvn4xw/J5Mm/T7tZfQK64Mh5TWPjFfKb3yyVbdvmy29+s1QaG69Iu0nkPGPPnlopLOyUzs5CKSzslN//vto+iIgIJyByntPcPFEKCjokivpJQUGHNDfXpd0kcp4xduzuePLp7CyU8eMb7YOIiOSxC66wsDD2nVq1VbQf2opbsHLDoW6APm8dx2DVEsJro/8bNSD0n5869aex66ikxI3j2bNnj2OjLxhzWaHmoPsM43Y2b97s2KgfjR8/3rErKiq8x2v/OepL6P/GdmIfY4wL+rj18xs/frycOXNEtm7tJwUFnRJF/WTmzBOxzuerK5VtO2pGOk4L/fQYJ9L12braFvYDxurocY39jTWWcFyhToNa1v79M2X//jqpqNgmNTWbnP2xT6zng9sRHEtaP8QYIWw3XgvfZdRBN23aFP+N8TE4DpHLL7/cu11fq6TkBfnwhzvk9dfHyZgxu2TevDMi8kf9FjUgqw/xN8eXAw/7QNeoEunah9ZvKaL3x3b7Yix7mjcubyegC53Dh+fJtm1LpaCgQ7ZuXSDvf/+3qF+cA3V12+V//a/HZc+esTJhwj6ZNGmnfdAFxM6dk2T16k9KQUGHbNlynVx77QMyfPhzaTerzzFhwjaZMOFsIcbx3n3JH6ELLk85enSa4zpqaZloH0SyUle3Xf7sz/5/Tj5ZaGy8BFyU70m7SeQCIm+/gLQLznKN+ErUIuhyw2WL2q0i0vXzV7s70B2E7ju8Fn6WottGu1aiaLfs398v/nEYMOB3TmoYPDeC6f5feeWVbu8Dyy/43D8iXfsb05i8+OKLjq3LNmOZCOwTdC+hiwGfPaZD0q4VK9UOukRx2S+Wc8CluxrsMxw3eB+YZsZy3+pngGMWQwlwHF566aWOrV1TFRVbZePGq+NxNmLEK864tFxsaGOfojtp8uTJjq1dk+iGxJRQ2Mf4PHBcajcnhkig2xn7H12kWFYCXXo6JAPPNWPGDMfGZ4t9jO+2b4k/jmksG289L8slp7eHpDXr6W9y3k5AFzqVlRtk9uz75ODBKVJaulmGDXvRPoiQQGprN8u8ef8sra2TpKxsi4weXS8g0xDSa3ACymMqKtZLRcV6ERExNFNCzpnRo+tl9Oh6e0dCcgw1IEIIIamQt19AnZ2dsf/RWlqtfeDoR0b/KfrPrZLcqAPo86HvHZeRIqj5oB6C/lu9ZBXvAzUG9LWjrxd1AX0+q8wypvXBc6Pmg7rM/Pnz479RL0Ib+xTT/KDv3ZfKHtPiW6WScQkrPk9cXq41IzwW7wuXYWMf47jDtmm9w1qejNoX9ikuXUe9Q2Ol0sFxiCUscGk0Pr+6uj/GZVl9hMdi6AFqePp4vMff/97NVGCFa2zfvt2xcZn9rFmz4r9//vOfO9tQ00GNCG2rJIzuh6uvvtrZhmmZ8Fh8ftiHqOvosYXb8HdBP2trmXt8zh7tRQghhOQYTkCEEEJSgRMQIYSQVMhbDaigoKCLH/wsISnErZghtFErwdgDrTGhRoDaCMYeYCoX9NX74m1Q40GftVXGAHUCfS3012IfoK8X+wzvG8tK6NQw2J/oV8a4BtTg0GeNepO+L0vfs2IgUMfB7VrDw3OjzoL3ZaUg8pVBwG2oV2AfY2oe7DMcG740Kvg+4bjE+8b7whRSWjOySlNjjBiODdRStOZqvS/YTry2NTb0+VG3fPXVVx173rx5jo3vn/VOaD0Q7wvfVUsbRhv1Kv288d3DPtHvG46p7uAXECGEkFTgBEQIISQVOAERQghJhT6hAaHf2acBheQrErFL1vrK0KJ/FbUT9BOjLoO+e1/OO9zXKuuL6//x2vo+sA/w2AMHDnivjbFVmOdM+7hRB6utrXVsjAVBnzaCbdG+Z3w+2Id43zg2UK/A56mfjxUjYaW9R5+5T9PDPkTfPNpNTU2OjeMM26qfJz5bjF2ztCu89jXXXOPYuk8x9xvqEagBYS44jDnS/WRpv/ieW/eFOqduK8YI4bPcsmWLY+PvG8by4PPWWgvqQ6g7ox4Vop+L+Evd+HQz63f1LPwCIoQQkgqcgAghhKQCJyBCCCGp0Cc0IIuQOCBLE0J/K/oy9flQK0GseBorNkRfC9th1RQJ0bqw//C+rLgRjLeprKx0bH1fqClgLBW2BUs4Y8wE2rrPsL99sTV4rEjXOkkHDx50bH1+7F+8T+xT1Dcs7VLnOcNaT6iN4H1Y+fNw3On98b6skvY4plGPwnx6+lrYDsxhh5oDapOoN+m4IHwX8flgn1nxNYgeS6hr4vvyP//zP46N7yrqbNjHOu8gtvuZZ55x7Llz5zo2xk7hO4DPQGPl5NQ2busOfgERQghJBU5AhBBCUoETECGEkFTIWw1IY61d98UBIegztXQm9MVr37FVXx394eh3Rr+0j1Aty8qDpm2sU2TFx6CegW3x6SEYI4Q1XFCDw3gLfL6+nGvoO7fq6OC1MLcY+uZ1HApqI1a+Nnw+eB+o2+jtqMk1NjY6tlW/Ca+NbdW6Gl4L24VxJjhOy8rKHBtrNOnxUF5e7mzDujiYO9F6Xvr5Y7utMYtgn+LY0ja+9xiDV1VV5diYu2/37t2Ofemllzp2JpOJ/0ad8vXXX3dsfD44hvG+sA/1bxq+P9iHWj/yaUnOOXq0FyGEEJJjOAERQghJBU5AhBBCUiFvNaAoikw9p6fnCbHRJ4oahfaDWtqIVXvD0nW0ba3BR/Bcvjou6M9G/62VJwv955jPzecbxnaivxz3Ry0Fbf1M8Fzo38Y+Rd876lXjxo3rtu3YvzgWrJgW1GV8NWBQl8G4IATvA8+N41hfCzU5zLdm5bBDDQJ1UD0OrfcJNR9fDJiI+y5bMWBWnA+OcXyeIXVz8FzTp0937JAYJKveGY4NvBaOO9/vo/Wbci7k7QREzk9aWmbL4cNTZeTIVySTWZt2cwghKcIJiIiIyKFDc+Xo0WlSXLxRyspe7JVrHDgwR1599StSUNAhe/b8lUybdreUlLzQK9ci5weNjVdIc/NEKS/fKpdeui3t5pAck7cTkHbBJXHFWa4ryy3mK1eMLh50CaCrA91F6M7QyyuR0OXlVrp512XwZ7J16z9JQUGHNDX9tRQWfklKS3/X7bXxWnhf6J44u8z02LHpItIhUdRPRDqktXWSVFSsd/bF54GuEnQX+lx46AqxUtDgcvQJEyY4Nj5P/fysFCdW+W9rnGrXFd4zuskwfRG6fNAVidv1Ul1reTj2Gb4v2GcYeqCfd9flyFNk48alUlDQIVu3LpBTp1ZIZeWGeDv2Mbr39LV37JgoLS2TJJPZIlVVG7s8exxXVgoivLYvFARdaDgucZzhu4slFrRrEs+N4xAlBHRrWu5C3RYck3jsucBFCEQOHrxMCgremRgKCjqkre3yXrnOyJGviMg7k49IPxkx4uVeuQ45Pzh06L3OuDx4cMo5nef1198rzz33j7J9+3Xy3HP/KG+8MS3HLSXnCicgIqWlr8YveRT1k+HDN/XKdTKZtXLZZV+Wqqr/kssu+7LzlUUIUlLysjMuS0s32wdlYf/+Omcia2mZmOOWknMlb11w5N2jvHydzJp1rxw8OEVKSzfL4MG9NzGUlv6OE08fYN++6dLaOlmGD39JysvXpdKGsrK1Mm3a/5FDh6ZKSckrUln56jmdp6Jim7z22p/Gk1AmszW3DSXnzHk/AYWkEBexl/1qPzP62lETwlQi6J/F41ED8vmVfcuqRez71MdHUSSZzNp4VdqpU67/G5fx4rUtX7D2xaM+hJqClSYGt2fTVlpbr5TDh6fKiBEvOwsqLA0O9Qmd9l6kq9ai06BgCn4sM4FaCfrurbLzen/UOiw/vqVv4DPYs2eqrFt32x9+sK+XGTPukUzmnUnISiFkpbjBpdR6POB9dXZ2SlHRFhk/fssfzuXeB4L64dl+qahYLwsWfEeami6VysrtMnbsDjl82O0jS0/C+/al9MJxhveMmg9eC0t24/un+wxDB6yQCnzWqBHh+6SfH+pH1m9KTzjvJyByYdHaeqW89NL/kYKCDnn99Zvk8su/0mur+s5XUBM8dGhqPAH1VcaOfUXGjn0l7WYQgBoQOa84fHiq8+N55MjUtJvU50BNsKSEP9ykd0g0Ad1///1SUFAgS5cujf/tzTfflMWLF0tJSYkMHTpUFi5c2CVjKyG9xciRrzg/niNG8MczlIqK9TJr1r0ybtyTjvuNkFxzzi649evXy7/+67/K1Knu/2Heeuut8otf/EKeeOIJKS4uliVLlshNN90kL7wQFnDoS8Xj0wGseBiMgcBzoR8Z08roWAX0G2PqefS3oi6A5YmxlLX2JaNmYMVfWL557RvGfbFPECsOyJdiyEo/ZMXuWG2prNwg/frdI4cOnc22sEHODnPc10qJgiW40a6uro7/xrGKfn8ch1YJbtzfFy+D6W6wbAGm7sFzZytbUVW1UaqqNv6hXd2ntME+tVK74DjWzxffPTw2tOy8bltouRLURvBdxz7W+ghqi6j1oqaD74/1ruvz19TUONtQP0LdBnVMK35NPwPsX9S8Nfgsu+OcvoCOHz8uN998s3zve99zgtaOHj0q3//+9+Wb3/ymfOADH5Dp06fLww8/LL/73e/kxRfphyfvDpnMOpk06f9jqh9C8pxzmoAWL14s119/vcyfP9/59/r6ejlz5ozz73V1dVJTUyNr1qzJeq7Tp09Le3u78x8hhJDzn2AX3OOPPy4bN26U9evXd9nW3NwsAwYM6LKcNZPJSHNzc9bzrVixQu6+++7QZhBCCOnjBE1AjY2Ncsstt8jTTz/dxW98rixfvlyWLVsW2+3t7Y5vPddYObjQB+pb74/bQnMl4fp/tHVuOSt3FYI6AfrudSyBFWOEWGXNQ9K04754X+hnRt885hrTOhvm5mtqanJs7G/sY7RxbGg7NFcfjg0r/kn3C14LNQTUSrDdGIuFOoFuq1XWHPvI0gd9ZexDYteytcVno/aL2geOM9Q7UJfB/fXzwnaj7oKaHT4f3B+fl24bXgv/5x9LdOPYsHIUWhqsxvfb2B1BLrj6+nppbW2VadOmSf/+/aV///7y7LPPygMPPCD9+/eXTCYjb731VhfRs6WlpUu997MMHDhQhg0b5vxHCCHk/CfoC+jaa6+VV19102F84hOfkLq6Orn99tulurpaLrroIlm9erUsXLhQREQaGhpk7969MmfOnNy1mhBCSJ8naAIqKiqSKVPcjLQXX3yxlJSUxP/+qU99SpYtWyYjR46UYcOGyec//3mZM2eOXHnllblrNSGEkD5PzlPxfOtb35LCwkJZuHChnD59WhYsWCDf+c53cnqN3qwPhL5fny5g+ait0rqY+23nzp2OrfUMq1Q4+vF9pY+xbaGaj4Xv+Vj9j+204kp894V9YsVloS6Dzx7Hhr62lVMQNZ2exkmcRWspvpot2a6NYFtQR9NY+p5Vn8k6Xvebpc9aMWTYD3o7jgUEn59VQh3fP60pYeA97uuriSTSNd7Ml38PVw1jn+B9h2pAPd0mcm4aUOIJ6JlnnnHsQYMGyapVq2TVqlVJT00IIeQ8hrngCCGEpAInIEIIIamQt+UYCgoKeuxH1L5J9IFamoMV64GxJHr9v6XxoH+8qKjIsTFG4vnnn3ds7etF/QGxfO+I9jtb5w7VgJAQzQ6fB/q/sY8xvmPfvn3x36jp6LRRIl2fj+Uf99WECc1hZ233xddYY9zSl6x8YHpc4vjHPsIxjDoMHu/L1xY6zkLGPIZ3YH42fDfRxnHmGzs7duxwtqHWi32AYwfvy5eXztJ8LN3M6nM9tkJrjPUEfgERQghJBU5AhBBCUoETECGEkFTIWw1IY8UHhIB+S/SXo405n3SONStOAfUK9P2iH3nixImOrXOXYW43rAOCcT8Yi4B+Zh2LEBq7EeI3zmZrUHNDjQFtjOVBPUNrDtj/qAHh80Bfu1U/yBdzFBrTYo1LDeoseCxuR50GdRlf3kAco9guSzezjg/RgJKMSxxnCPYZxtdgrBT2aUNDQ/w36kUzZsxwbOwz1BYrKiocG8e47mOMV8JnidvxeWC/+HL1heSJ69V6QIQQQkhSOAERQghJhbx1wfmWYSdxyVmuDnRV+VwnlnsIbbwfPHdVVZVj689pdKmhjeXAMd0HtsX3+Wy5NtBlZ6Hv00ojg88DM6ujjeglxeiWDHUd+lLviLhttc5tLffH7b6UQ6FpfXB/q1yA3o7uIDwXPg+rTD3u73PBWePMep806ErHktr43mP9skmTJjk2umu3b98e/11bW+tsw0oA6ALFPsN3F1Pz6H7B9wdBtzO6Ei13bkiqJF9pje7gFxAhhJBU4ARECCEkFTgBEUIISYW81YB85LIcg2/ZoUjXZYt6yST6cq1zo58fr4WakvYdo6/2wIED3nOhnlRcXOzYR44c6fa6VunjJOk8sI8s3cyXhkSka4oV7fPGduK5Le3E0oC0bmAt2cZrYZ+GpLrHZ433ZfnqsQwFakB6PKBmY4UWYB9ZZRB8KYZCtUbEN+4sLRiXWe/fv9+xUZfR42706NHec6ONfYRt86XqwWePfYbvB/6eYb/4tEgrBZQvbU938AuIEEJIKnACIoQQkgqcgAghhKRCn9SAQrD84WijHoLaifahoh8fYw1Cfdroz9Vr9q14DPRJ796927HxPvS5UWexSh1bmhDi88UfOnTIsVFXQ581alsYM6GfAfrWMeUJpkxBUM/w+cCxT/Ba6Mf3pfXJhr42jlHUFHAchYxpEfeZ6HRQIl01herq6m7bKSLS2trq2BibpbHieqztPhu1K9RQ8b4qKysde+3atY6N2th1110X/43pb/B5YH/jfVmxiHqs4LmtNEyW9uhLlYSExGF1B7+ACCGEpAInIEIIIanACYgQQkgq5K0GFEVRj32K2ifqK2WM+2az0TePuo5uE/r50f+NbbHS/aOt/buoR6CPGsv+Yjp51Ih0Ljn0y1uaD7YzJN4JnylqOHhfWBrZ0k70dvSlY6p6Kz+bVXpAP3+8Lxw3VlkCqy3atnIQ4nZf/JJI1/xg+hngNh0/JiKyZ88ex0YtBW3slxCscenT7PD5YKwOvh/PPPOM91ozZ850bBynGnweCP5uYFwWvsu+HITWOMN2YttwHGo9y4pX0v1v5ag7C7+ACCGEpAInIEIIIanACYgQQkgq5K0GpAlZXx4aK4CE6B2WFmLFMVh1WrRtxZGgreviiHTVWrSv9/Dhw952W7ECCN6XbptV+wTvA+MYLD1D27jNyktmlW32PU881oq3sGLEfPEXVpwWgn59K9ZD6z54X/h8UFeztEccl/perD604s185cGxD7DeD+qzqKmOGzfOsX31tnDchWhV2dqC76eOacJz+/LGidh56Xw58qx9WQ+IEEJIn4ETECGEkFTgBEQIISQV8lYDCokDSnodjaUhaT9oqDYSWlfH53+1avhgjBJqKTpeAGM1EPTnhupoui3o/0bfPNqh+fR0nAn60tE/jn1kxZkgPg3IignDa1tjyTfuLN0StS8rBkkfj3nNMKcajh3MkYaaEMYR+eoBWXFyiE+7tOJh6urqHHvUqFGOjfFLe/fu7fZ8Y8aMcbahhmNpwXgfqLvpvJCoqWFcFo4z69n7xqGlAelzWb+FZ+EXECGEkFTgBEQIISQVOAERQghJhT6hAVk6Teh5Q+wQ/SNUT7LOrW3rnq2aML41+1a+taQ1RbRvGLUrPBdut3QBXxwQ7ov3iX2C/nLsB0Rvxz7y5fXLdm1rbPjyiVkxYaGxIVrvwG3YRxgPgza2G+vw6PNbdY4s7QvvW29HrQrzH1o5INFGbUw/f6xxFZpj0Mr7OHHixG7bvXXrVsfGXH4+3UbEPw4tXcenF3UHv4AIIYSkAicgQgghqXBeuOBy6ZKzPvu1+yLpMlErLUZ31z0X2+c2w+XK6E4KBT/rtYsB7xHTxyd1Y+r7RDcJuuBwSbDl7kPXiG47Lk+2xgbeh+Wm0ftjO9HNYo1hC18KKGspLo4dtDGljc89a7mHsB+sVD6+c2EJBLTx+Y4YMaLbc+O4Qvcfttsq14Dj1lf6Abehq9GXakfEX74Gjw3Ztzv4BUQIISQVOAERQghJBU5AhBBCUqFPaEC5Pm+I7VsuG5o6xLqWT6fBfS3/uLWkWF8L/cAhvnQROw2QtnFfq0w5ElJaILT/cak0nhs1Jd1PVnoV1LowPY5VOl7rBNbyY9QrrNLwvueF57b60Cp5gW3xYS33xz7ylYw+ceKEs81KVVVSUuLYuAxbl7QXcfvcWoqOWEuWcWxojQnH1dixYx07dBm2r20+vRX35TJsQggheQ0nIEIIIanACYgQQkgq9AkNKJdakHWukDLZ6Oe0Ym8szch37dAy2Ri/YcWdaCx9CbG0L90PVv9aZc4tWx+Pmg7qAJYGZD0/rY9Y6W6slEOIr+3YR6j54H1ZpTt84xDHiTVmESvtTEhcnaUB4bjV21ELsUp1oN6Hx6MmpO8Lnx3qNAjuj32KepUu74DPB+OTQssx+HQdX9kO3N5TrY9fQIQQQlKBExAhhJBU4ARECCEkFfJWAzpXLL8xYuWX8mkt1rp4S/PB/TGOQR8fem4rnka3PbQ0tRWzEhJrEKKDZbN9MTGo+WC5aMyThfsj2E+6rZaWhXEmVs471Ciw7Rq8D6sURHl5ubdtvtLK2N94LMYNWfnafJpqaE47n16F2hO2E58fjgUrrkU/A9R8rPcc885h21CP0hqQVfrBep+sXHC6z613kXFAhBBC+gycgAghhKQCJyBCCCGpkLcaUP/+/WN/Zkg9oCRaSLZroS9+5MiR8d/oW0df7eTJkx1b+25FRLZv3+7Yvjo8VgxEqJaiz4c+afQjWxoREqLDWbVR0A7J5YftxFgOvC/M/2XVA9Jjw/Kl41hBfDWURPxaybFjxxwbx2Fpaalj+3QYETcmxtL/rHiPkPin0LyMlp4RkrfRimdCfP2CMUVWrsTQ/Hr6vrH+j6WbWePQet985/LlruwOfgERQghJBU5AhBBCUoETECGEkFTIWw1IExrLk2RfK1ZHY+kwlpZixRz5zm3pYtb2EEJqJIn4/dDWuSwfdqhOoLH0CCvGyNfHVtwDnhvHAuIbS1aclq/2E54rG3pcWtqI9fx8z0Mkt3kefWPceletcYX49sdtqO22t7c7NsZ4oWaH59OaH+Z+GzduXI/bGWon2bc7+AVECCEkFTgBEUIISQVOQIQQQlIhbzUgXQ8o9DifHbo/+tN9uZHwWCsOxfLF+86dVBMKuZYVfxGiAyStVYNgHIq2rT6xavbg8/HFz1j9belJiK+tlgZk1fDB5+XTeZLG1Vnn8xH6LvsI1aJCfzd8cVoYx4NjHuO4cDvmitN56srKypxtGMsW+u76+iHkXNSACCGE5DWcgAghhKRC3rrgNCGfw0mXHVruCV+qesvlg6WT0b2HKTySkMTlFrKsOtt2dIv5lijjPaP7CN1LlgtPn89aGo3LY61l9L5yxZYLDs8VutxcX9tql+VyQ5eQ5dILIbSsdghJXHKWq8m6luU6DHHNY4quyspKx8aUXfi8demHmpoaZxsu77fKSoS45EJc7SzHQAghJK/hBEQIISQVgiegffv2ycc+9jEpKSmRwYMHy2WXXSYbNmyIt0dRJHfddZdUVFTI4MGDZf78+bJjx46cNpoQQkjfJ0gDOnLkiMydO1euueYa+eUvfymjRo2SHTt2OOkgvvGNb8gDDzwgjzzyiNTW1sqdd94pCxYskC1btnQpVetDL8N+N1PxoO8S/a8h6eRRC0ENCG30zSchSSoey4dtldz2aUBWH4W2DZ+HPp+19DYpIT7v0CXhvlLxoUuhsY8tjcj3joQs4c5GSOiBRUgappDlxiLhy899aZnQRt1m0qRJjn3kyBHvtbV2jHodpvlJEjIh0vsluYNGw9e//nWprq6Whx9+OP632tpap7ErV66UL3/5y3LDDTeIiMgPf/hDyWQy8tOf/lQ++tGPhlyOEELIeUzQ/778/Oc/lxkzZshHPvIRKSsrkyuuuEK+973vxdt3794tzc3NMn/+/PjfiouLZfbs2bJmzZqs5zx9+rS0t7c7/xFCCDn/CZqAdu3aJQ8++KBMmDBBfvWrX8lnP/tZ+cIXviCPPPKIiIg0NzeLiEgmk3GOy2Qy8TZkxYoVUlxcHP9XXV19LvdBCCGkjxHkguvs7JQZM2bIfffdJyIiV1xxhWzevFkeeughWbRo0Tk1YPny5bJs2bLYbm9vl+rq6iANSJM0pYa1XfvTrfgL1HSGDRvm2Fg6GdOyh7QrSXr50D6w4n5C4oAQS7+w7sunlaBeYaWsCU2f47sWnssqEe0rHxCyr4idFgjR5/NpbNmuZYE6cJIyIUiuSglkI0QTsvobS1ljPCDavt8VS1MNLX/i04Cs34Fz0YCCvoAqKiq6CGYTJ06UvXv3iohIeXm5iIi0tLQ4+7S0tMTbkIEDB8qwYcOc/wghhJz/BE1Ac+fOlYaGBufftm/fLmPGjBGRdxYklJeXy+rVq+Pt7e3tsnbtWpkzZ04OmksIIeR8IcgFd+utt8pVV10l9913n/z1X/+1rFu3Tr773e/Kd7/7XRF551Nx6dKl8rWvfU0mTJgQL8OurKyUG2+8sTfaTwghpI8SNAHNnDlTfvKTn8jy5cvlnnvukdraWlm5cqXcfPPN8T633XabnDhxQj796U9LW1ubzJs3T5566qmgGKBQcpkLLiTGAnOJoV8f85yhL7ioqMjbFh+5LMcQ6g9PkuI9tJ2WL9mnteC2UA0oJDbHOjfm6EI/P273+eYtzQ0JKf2e7doaSwux7CTntsilVhx6Xz4w1xs+65MnTzq29buhNSA8F8YWHj9+3LFz+e76ju1pDF5wVNiHPvQh+dCHPtTt9oKCArnnnnvknnvuCT01IYSQCwjmgiOEEJIKnIAIIYSkQt7WAzrXktxJCfHtoh8ffbXom0dfPPprQ0haojvJuZLaIdey9veVo7Zib0LHV0icCYLXRv3Qis8IyXFnaVkh+fesc1nxTqExS5pclpkPJYnWZeXLw2ePz9oqU6/HOB6L9X+sMR9iJ9m3O/gFRAghJBU4ARFCCEkFTkCEEEJSIW81oIKCgm79wz7/a0jdDhHb9+7zeeMae4x1Ql/vqVOnHFvXURIRKSkpceyzKY6yMXz4cMdGvzHeJ8YL6FgCbCfGsGAfYZyCpXX5fNbYbtTFsC1WritfLji8NuoVeJ+4HftJXzs05gvB47Ht+ngcZ0ePHnVsq4+s/F8avA/LTpKTELFqDVnbfbVsQs9laVd6nOLz0SVrRLr+biDYp74+s977kDifbNv1WAmpG9VT+AVECCEkFTgBEUIISQVOQIQQQlKhT2hAIWvwk+aqCiG0jo4V1zBkyBDH1poD+notn7blr9V+ZtQErD4JrXXja4e13Yr7CYmXQW3EqouDcV6+tqHGhn2ANWBQB7j44osdG7UvHd+B94XjBscKxoZgyRNfzR/sX6xxFRJTJNK1BlZIHFDodg32J4J9gM/PGgsaK74vaRydfv4h+2bb7qvpg8db59J2r9QDIoQQQnJF3n4BEXKh8MYb0+Tw4fdKZWWDjBnzctrNIeRdo09MQLks22udO8my0VDw3Lgs+8CBA/HfR44ccbZZrg/rU9vngrNSiSQpVY3tQncFXgtdI+jKQlv3S2ipcOs+0Y0TUv778OHDjn12/5aWWbJhwz9KQUGHbN48X973vv9Hqqo2dlnKq/sN3UHYh7hc3Gqbbzl66Pi3So0nGStJUidZbmJcBm+V1faFHmCIBJKkJAJut1zxuSzRHeKC62k5BrrgCEmRQ4emSkFBh0RRPyko6JDW1kn2QYScJ3ACIiRFSkpeiSefKOonZWVb0m4SIe8afcIFR8j5SiazTmbMuEeOHZshZWVbpKpqY9pNIuRdI28nIF2OwdIkkpTktvyvuUwBb7Vl5MiRjq3Tr6AGhMthcRlwSCnkUF+7tXzZ16fWubE8MS5Xbm9vd2zUgPR9WnoEajqoraD/HJcz63uxruVL89O//y+lqOi/5dQpkR07srdFL51GzQevhceinmTpIb6SFoh134jvfcplmQ8Lqw+s54fvk34m+B5bvzk4zpJoLaHLsEP0KJZjIIQQct7ACYgQQkgqcAIihBCSCnmrAXV0dMR+2BA/puW7RUL8raGEngtTqhQXF8d/o18fSzugBoQ+boyn0T5sPDY0hRBipffQoMZjaUC4HeM3NFYcD5ZIwDQx+DywH3SfWr50q09QX0JtS98n3odVNgI1I9QofHFCoc/aGju++KZQvSIEqxSHVQLBN85E3FRKOI6SlEDItn/IuXpTR0NCyuKchV9AhBBCUoETECGEkFTgBEQIISQV8lYDEvmjf9LyU4ZoQFZcT0jMUWj575D7EHFzSmF+KYwDCmm3RWj54pC4htBSD1beM1/ZA9RRQmMg8Fr4DHTbLN873ndbW5tjl5aWOjbGfTU1NcV/ow6Gmg62paWlxbGxX1AD1PdtlWv3lawXCXvfQnOihcQc4bFWHB2CGhDqh/oZYB/hsUl15xDdzHfsuWzPNfwCIoQQkgqcgAghhKQCJyBCCCGpkNcaUHc+3lyW5EaSrJNP6l/F2B6tOWQyGWfb0aNHHRt1F+u+ddyDVTPElytMxK4npG08FmMmLA0BNSFfLRtLU8A+xP5HraWsrMyxdZyQVXMHtRTUZfC+jh075tgYD6WxymRjjBHqHT790Hoe2P8hz0ckTM+w3h/fu43jDp+1pW3hGNcxeiKuhme9D6H3kSQOKGmuuJBcfT3dpuEXECGEkFTgBEQIISQVOAERQghJhbzWgM4Sst4/VPMJqVGfFMsvir587WfGWA/UFPBYS5PQvnr0h1sxRZaP2hevEVo/xopJQs1B5+TCXG6oR6DGg7WGDhw44N1fXxv9/qgpYFvwWhgrgufTug2ey6prhNoV6m54vL6WVQ8I9SYEnx9eK0k9IMQ3llD3Qo0N+9sal9iHul4Tnjs0tiZUp/ZtS5orLqSWV0/bqOEXECGEkFTgBEQIISQV8tYFV1BQ0O2nKH7e+dL9h7qTkizjxmthCQTLHYGp6rV7Q3/ii4iMGjXKsTF1C7YTz43uJN+x2N9Wihtf6WsrVZJVPhrdhb4y2Za7Aa+FbbNS8GvwWaJLFF1uJ05cK2++OUcGDVojgwc/7XXpiPiXfIe6pvBavuOtVFYWVgqcEJK4ptBViM8ef0NwjI8ePdqxMXWSdruhCxSX0Ie6yXzjOEl6omzH+/bvjTQ9/AIi5F3m5Mn5cvDg9+X48Y/LwYPfl1On/jTtJhGSCpyACHmXefPNOSLytrzjgHhb3nzzypRbREg6cAIi5F1m0KA1cnbyEekvgwa9mHKLCEmHvNWANKF+ziTntrZrfyzqSahXWGWyfSWe0cb075MmTfI1W3bu3OnYmP5fL1fG64ZiPZ9zTechYvcx+tv18/FpgyJdn49VmjwEfF4uW6Wk5HZpb79Chg17SUpKGqSw0NUUsA/1M8L7wj7C+8A+CvH7h75rScpqh4ZQWOhrY9ol1HBQ88E+fc973uPYlZWVjv3GG2/Ef1slQywdBrVH3xJ9K01W6PMI0ZtCtMPu6BMTECHnGyUlL0hJyQtpN4OQVKELjhBCSCpwAiKEEJIKeeuCi6KoWx9jEt98SNqYbNu1/zVpyWD05aO+4dNmMI4BbWybpRskISQ1T2jMilWi2+drxv6z4sfw3L60MSL+NDR4LtRlrFgqbJvvWlbaH9QkcpnaytIQkJDSD0lTQGmsNEwI9r8uiS7iLzuB/X/w4EHHDo01xLRbum04Lqwxn8tUPLnQgPgFRAghJBU4ARFCCEkFTkCEEEJSIa81oLN+xCRxQKEp3q18bRr0E6P/1Sp1jbaOzRFx82YdOnTI2bZv3z7H3rNnT7ftFOkal+KLkenNEhV4z1a6/9DyDb598Z4xrxxijQ2fRmf5wFGDsOKbtK5g6UuoGeD+VukB3eeh5TLQ3rdvmrS2TpGyss1SWVnf5Xjf+ZPmndM2jv/GxkbHHjdunGPjfTz99NOOnclkHHv69Onx35jvDjUhK84Hwd8gPVYsrTc0zjGJfnsu8AuIENIr7Ns3XV544XbZufPP5IUXbpempun2QeSCghMQyVv27ZsuL730d7JvH3+4+iKtrZOloKBDoqifFBR0SGvr5LSbRPIMTkAkL9m3b7r89rf/W3bsWCDPP/9FTkJ9kLKy1+LJJ4r6SVnZa2k3ieQZea0BnfU55tL3aPn1UbdB37z2j6O/1fL7W7E3GBty+PDh+G/UeHbs2OHYWHOkvLzcsVEn0PvjPVpxCSH5vSy6y4+H//d84MBkqanZlEifsspHW/dl5ZbzXQvPZeVrQx1H274xmQ3UqlBTsGKvNCGaQmXlBpkz5345cGCyjBr1mpSXb5CCAr/m11tgH+A9Y9ly7OMNGzY49qZNmxxbv08jR450tr3vfe/znhttS6vU2/FYfLYhNa3SIG8nIHJhk8lskYaGD8aTUCazNe0mkXOgsnKDVFZusHckFyScgEheUlW1Ua6++v+VlpaJkslslaqqjWk3iRCSYzgBkbylqmojJx5CzmPydgLq7OyM/bS5rDdj2ei7R9+8xqpVg9vRt4vxAs3NzY6tYxVwGx6LueB89WR6m5AcUaH6npUbTt837ot9gDoMbrf85/p5h+ZIw3ZjW3254SyNzoqdsrbnMg4s9Nqa0NpRvu2okaLmg+D7NX78eMfGelu7du2K/8YYr9WrVzv22LFjHfuSSy5x7OLiYsdGDejYsWPx36G6Zqgdcu5zOQ9XwRFCCEkFTkCEEEJSgRMQIYSQVMhbDcgXB9Sb9YCs/X2xIOjfRr//kSNHHLu1tdWxdV15EbeOCPp6MbeVrz6JiL/GCPq7Q+uwhOg6eC7Lh41YMRTaxpgIqyaPpYUkyZ9n5cBLkuMO7xNtS1/ynT9p/aaQPI4h71oo2N+Ynw3fAR2Dl+34MWPGODa+y5otW7Y4NmpE2Cd4bl99JxzDqFta2iTrARFCCLkg4QRECCEkFfLWBafJpcvNcidZZZh9bgHcFz+H9fJJEZHdu3c7dnt7e7fnw89wq524Hcsy609kqyxBaEr+EBeclT7ecvH4bHSbWGmXrGX1vvvEdlpL8n1lPrKdT+9vuSEtkqROQpK64PT2pEv0fW0bOnSosw3fTQxjQFpaWhwbU11VVVXFf7/2mpvzrrKy0rHRbYb7o6sel22XlJTEf+M4wlACq0+tcAGfCw7xPcvu4BcQIYSQVOAERAghJBWCJqCOjg658847pba2VgYPHizjx4+Xr371q10yEdx1111SUVEhgwcPlvnz53fJ3EwIcWlqmiGbNi2SpqYZaTeFkHeNIA3o61//ujz44IPyyCOPyOTJk2XDhg3yiU98QoqLi+ULX/iCiIh84xvfkAceeEAeeeQRqa2tlTvvvFMWLFggW7ZsMf2smsLCwm7Twvv8yqFpSnD5Mi6RRO1EL3/GbagpbN++3bFRa0F/Ldq+FPwI3gf6htEnq/tl2LBhzjb0j6PP2loeG6JJWKmPrLIFSIjPGp8f3rflx9Z9bC19RnTbmppmyJo1t0tBQYfs3PkhmTv361JdvcnZX/eppQFZy+hxnOHz1M/E6oPQ5ec+jSKp/ue7tlXyHPVZTIeDIRIjRoxwbH0ftbW1zrb9+/c7dmlpqWPj7yKm3cI0Qrp8OJ4L+8xXhiUb+Lz18nTU0XDMHzhwIOtxPoK+gH73u9/JDTfcINdff72MHTtWPvzhD8t1110n69atE5F3HvjKlSvly1/+stxwww0ydepU+eEPfyhNTU3y05/+NORShFwwHDgwhZVDyQVJ0AR01VVXyerVq+P/s3/55Zfl+eeflw9+8IMi8s6qrubmZpk/f358THFxscyePVvWrFmT9ZynT5+W9vZ25z9CLiRGjdrMyqHkgiTIBXfHHXdIe3u71NXVSb9+/aSjo0Puvfdeufnmm0Xkj5+OmUzGOS6TyXT5rDzLihUr5O677z6XthNyXlBZuUHmzv26tLZOlrKy16Sysl5E0qkcSsi7SdAE9OMf/1geffRReeyxx2Ty5MmyadMmWbp0qVRWVsqiRYvOqQHLly+XZcuWxXZ7e7tUV1c7GpDl+9W+XvRnWzoL+p3r6uocGzUKbVtll3E7tg1t9Ndq2yqjHOqL1zaeG9udNJ2HTxOy4oAsDcEXV2L1kaWlWJqlHochZQawnSIiY8e+KmPHvvoHa4B3zFvah0/vEwkrJR+is2Q7F9q+siChY9p6nno7Pksc46gHWmMBY3V0bA7eI5Z+wP5H7RF/BxCd9gffXYw5wnaiBoSl31EP1s8XY6Hw2hdffHH8d09TSwVNQF/84hfljjvukI9+9KMiInLZZZfJ66+/LitWrJBFixbFwVktLS1SUVHhNPzyyy/Pes6BAwd26QRCCCHnP0Ea0MmTJ7NGi5/9v5za2lopLy93CjC1t7fL2rVrZc6cOTloLiGEkPOFoC+gv/iLv5B7771XampqZPLkyfLSSy/JN7/5TfnkJz8pIu98di1dulS+9rWvyYQJE+Jl2JWVlXLjjTf2RvsJIYT0UYImoG9/+9ty5513yuc+9zlpbW2VyspK+Yd/+Ae566674n1uu+02OXHihHz605+WtrY2mTdvnjz11FNBMUAi7/hoz/ofLd1Gf5VhmQLtmxXpum5+5MiRjo3+WYwL0r5jK++SL74im419pGMV0CcdmuPOpwuExpUgIZpQaInm0BLCvpgwK0+ZVdYglyUUrBLpIWULQnOohepuPkJ1T4wP8ZXPsK5llaXQ749VKsUaG/g7cujQoW63o4aD58K4OgTvC/tMH2/FNU6ZMsV7rtdff92x9+zZ49j69xRz0mFc47nEAQVNQEVFRbJy5UpZuXJlt/sUFBTIPffcI/fcc0/IqQkhhFxgMBccIYSQVOAERAghJBXyth7QmTNnYj8trk3HQNfRo0fHf6MGhP5X9FHjdiyt64vdCdUnkJC4FMuHHYqvbVbtGivPnKWFadBfbmlCVkyY3t/aF9tplfD26QShecysfHq+sWT1t6URIb7nFXpuK8YopFaUpQcivnGLugs+a9QzMCMLxtc0NTU5to6vQV356NGjjo1aL773Vh/q/bGdmH8S43503SIRkZqaGse+5JJLHLutrS3+e9u2bc62EydOdHsuS+c6C7+ACCGEpAInIEIIIanACYgQQkgq5K0GNHPmzNgHjz5TrEuh8zhhfMXhw4cd++DBg46NfkxLF/DVo7F889a5fD7uUH0pJJYDdTHE0kbwPjG3lU9TwOdlnRv7zBezZOkVeC5Lc7By+XXXjmyE6hshJI0L0s/PyndoERJrZdWRsnQ2n+6GcSn4G4Lxfr///e8de+LEiY6N96HzpI0aNcrZZmmJSIgWic8DtSzUgPC+GhoaHBu1riuvvDL+e+rUqc62LVu2OLYuPNor9YAIIYSQXMEJiBBCSCpwAiKEEJIKeasBjR49OtZ+0K+J9dv1mnzc18q5Zflnffm/8NzW+n28FpahQD+0j1ANyOc/t/z62AdWXJBPU7J0ldCaML4YiaQ57VDLCtHhrLif0Bx4vm1JY3VwHPs0IMSKtbJylVnPxLdvyPO1jsU+wDifCRMmOPaQIUMcW8fLYP/qOjkiXXVpHGcYy4h95vtNQ21r3759jj19+nTHxrbW19c79u7du+O/r7/+emfbtGnTHFvHEJ04cULuv//+btt5Fn4BEUIISQVOQIQQQlIhb11wDQ0N8adnSIoO/NS2lvWibVVn1S6J0NQglrsh1GXkI0mKfau/k5RKDk2tY7nFfO7B0HQ4oamTfKUfrFIcVsp+n9vMKuthuYJDSsVb5dVDS1b43t3QdEYh7wv2N7q70aWGy4gxRRe6urTr3yr1gC41fB54bV8ZCux/q/QDLrseM2aMY9fV1Tm2Tr/z0EMPOdv0Em0RkWuuuSb+23LdnoVfQIQQQlKBExAhhJBU4ARECCEkFfJWAxowYEDst7V0AG1b/ldLV0H/q883b6UZsZbWWnqGtn1lyLNtR3zbrRQooen/Ed3WUB3GKp+Bfax9/bnWgHzPx9KALE3IWp6u98djcVluiMaT7dq+cu1WOqnQ5eW+98kqCxJSmgPvA8sYYMlt3B9LcOPS6uLi4m7bgc8Hr4W/OXgtDC3R5R6s+8Iy2rgsW5fRFhF5z3ve0+3xr732mrPt5ZdfduwjR47EfzMVDyGEkLyGExAhhJBU4ARECCEkFfJWA2pvb/eWPtBonyuu97d80JaOY8VU9HRbT64dUrbZl4Im27mwH/TxoWliLF3ApzGE9gFe24qZ0DZuw7Ghy3iI+DUeqy1WbJQV34T3hfqgjufAbagxWBqdVdJCP08rzgex3gHf88U+tMoShKT1QR0lk8k4ti6n0JNrlZaWOrYvFQ+OMzy3FROGJb31tfDcGJ+kdRkRu1z4nj17HHvcuHHx3xg7heW/9bVwjHYHv4AIIYSkAicgQgghqcAJiBBCSCrkrQZUWFgY+3RDSvGG5i0LLbvsy5OFhLbF59MOLYVs6QA+fcnSZZCQ/G7Ws0Ss/F+oE/i0LdSEUHextC7ffYWOM6vUtW/chY4FX6yUiL+PLU0OsTS+kBIW1rVCrm2VgkfNAscV5ogMKdOCx1qaKz4fjDnS58dxpPUh69hs4PFvvPFG/HdZWZmzDft7165dPb7OWfgFRAghJBU4ARFCCEkFTkCEEEJSoU9oQBZJNKDQOCFfTEtIOe9stq8WkZW/y7J9ZZiT1B3Kdjzet88Xb/n9Q21fzrSexiZ0d27f9lC9IomOY/W3pV1ZNa+SaFshpeDRDq01FKIZYTtQD8SxgX2Etk/LsrRFq1YOjg3UhHQ/YGwO1v/Ba584ccKxsQ4S9oPWgLBWUEVFhWPv3Lkz/run9cf4BUQIISQVOAERQghJBU5AhBBCUqFPaEAh8TYhNeitc1l2aI40SxPy1Xf31YXPRkh9mZBYjWzXDqnLgue2cosh1rV8+kWu9QyfHmhdK1Qf9NVUCh1noXFdPnrq6+/u2rqtVo40K4edD6teE75fgwYN8p4PtRfftXx5GEW6xsyg7eszK58hPh88t6VD6/xujY2NzrZRo0Y5dlVVVfw3c8ERQgjJazgBEUIISQVOQIQQQlIhbzWggoKCbn3RIX5nKyear0a9iD/+JsRvn80OiUHKdd45fZ+hMSyWhuDrM6uOUage5etjX544ka7xGKFjI1T/0ITGN+n7Co37sWoRWW0LIUluv9B6TCFY4wz7BLUQHCs+DQi1qtB319JtNHhf2G6Md8K4Hyv3pb4XrB2E7RwxYkS31+0OfgERQghJBU5AhBBCUiFvXXBRFMWfeCFuGctNgtutJZG+a4d+1iOWy04fb7U71L2nj09zGbZ17lB8y5XRxjLNSJJl2ElLj4e4qkJdvVaqfJ+b2SJJKixrzFruIt+1sU/QpYZ9YrnR0AXnc/3itfDcuNwcwSXNIb8L2O5hw4Y5dnt7u2MfP37csYuLi7ttJ7rZ9LFchk0IISSv4QRECCEkFTgBEUIISYU+qQGFpqXRWCk4fKWq8VpJU73gtX2peEJ1mpDl5dY9W0unrfIAPl0G/ePWua22advSRtAXj4Qskw/1xeOzTpKKJ3QcWn2aZHm5dazv+YaEDmTD12dWOQbUAzEVj5X2Rz9P7N+kGqtPa7Z0MSsUwbqWBu8Lr6VLPVADIoQQktdwAiKEEJIKnIAIIYSkQp/UgHx2SPxLNhsJ8cWH6hchKfxDNR9ru75vSwMKTd/v6xfcZqWet/zpSEiMBGpAoelxQnzxVtwW4hsLoeXZEYznyGV8E2KVHNF2aOqdkHLflgaENpY5sEpBaNvSdi3d2Srp7XufrHcR43zwPnQ6HRFXy8FjfaXCrfEd79ejvQghhJAcwwmIEEJIKuSdC+7sp7J2zYSkuAlN5xHqkvMt7fTtmw3LLaO3o6sK7yM0/Yr+zMdtSVMIYdv0+X3tyHZuxHqevn1DXDY9sdNyweXaLfZuuuB8Y81aIhya3sjXx9Y4tCqH4v667b7UOdnOlcQFZ70PIf2f7Xx6f8tVr9t19jhrfOTdBHTs2DEREfnlL3+ZcksIIYQk4dixY04+OaQgShJ11gt0dnZKU1OTRFEkNTU10tjY2CWBHslOe3u7VFdXs88CYJ+Fwz4L50LrsyiK5NixY1JZWen9Es27L6DCwkKpqqqKs7QOGzbsgnhguYR9Fg77LBz2WTgXUp/5vnzOwkUIhBBCUoETECGEkFTI2wlo4MCB8pWvfKVLjXPSPeyzcNhn4bDPwmGfZSfvFiEQQgi5MMjbLyBCCCHnN5yACCGEpAInIEIIIanACYgQQkgqcAIihBCSCnk7Aa1atUrGjh0rgwYNktmzZ8u6devSblLesGLFCpk5c6YUFRVJWVmZ3HjjjdLQ0ODs8+abb8rixYulpKREhg4dKgsXLpSWlpaUWpxf3H///VJQUCBLly6N/4391ZV9+/bJxz72MSkpKZHBgwfLZZddJhs2bIi3R1Ekd911l1RUVMjgwYNl/vz5smPHjhRbnC4dHR1y5513Sm1trQwePFjGjx8vX/3qV7skd2WfKaI85PHHH48GDBgQ/du//Vv02muvRX//938fDR8+PGppaUm7aXnBggULoocffjjavHlztGnTpujP//zPo5qamuj48ePxPp/5zGei6urqaPXq1dGGDRuiK6+8MrrqqqtSbHV+sG7dumjs2LHR1KlTo1tuuSX+d/aXy+HDh6MxY8ZEH//4x6O1a9dGu3btin71q19FO3fujPe5//77o+Li4uinP/1p9PLLL0d/+Zd/GdXW1kanTp1KseXpce+990YlJSXRk08+Ge3evTt64oknoqFDh0b/8i//Eu/DPnPJywlo1qxZ0eLFi2O7o6MjqqysjFasWJFiq/KX1tbWSESiZ599NoqiKGpra4suuuii6Iknnoj32bp1ayQi0Zo1a9JqZuocO3YsmjBhQvT0009Hf/InfxJPQOyvrtx+++3RvHnzut3e2dkZlZeXR//8z/8c/1tbW1s0cODA6D/+4z/ejSbmHddff330yU9+0vm3m266Kbr55pujKGKfZSPvXHBvvfWW1NfXy/z58+N/KywslPnz58uaNWtSbFn+cvToURERGTlypIiI1NfXy5kzZ5w+rKurk5qamgu6DxcvXizXX3+90y8i7K9s/PznP5cZM2bIRz7yESkrK5MrrrhCvve978Xbd+/eLc3NzU6fFRcXy+zZsy/YPrvqqqtk9erVsn37dhERefnll+X555+XD37wgyLCPstG3mXDPnjwoHR0dEgmk3H+PZPJyLZt21JqVf7S2dkpS5culblz58qUKVNERKS5uVkGDBggw4cPd/bNZDLS3NycQivT5/HHH5eNGzfK+vXru2xjf3Vl165d8uCDD8qyZcvkS1/6kqxfv16+8IUvyIABA2TRokVxv2R7Ty/UPrvjjjukvb1d6urqpF+/ftLR0SH33nuv3HzzzSIi7LMs5N0ERMJYvHixbN68WZ5//vm0m5K3NDY2yi233CJPP/20DBo0KO3m9Ak6OztlxowZct9994mIyBVXXCGbN2+Whx56SBYtWpRy6/KTH//4x/Loo4/KY489JpMnT5ZNmzbJ0qVLpbKykn3WDXnngistLZV+/fp1WYHU0tIi5eXlKbUqP1myZIk8+eST8pvf/Eaqqqrify8vL5e33npL2tranP0v1D6sr6+X1tZWmTZtmvTv31/69+8vzz77rDzwwAPSv39/yWQy7C+goqJCJk2a5PzbxIkTZe/evSIicb/wPf0jX/ziF+WOO+6Qj370o3LZZZfJ3/7t38qtt94qK1asEBH2WTbybgIaMGCATJ8+XVavXh3/W2dnp6xevVrmzJmTYsvyhyiKZMmSJfKTn/xEfv3rX0ttba2zffr06XLRRRc5fdjQ0CB79+69IPvw2muvlVdffVU2bdoU/zdjxgy5+eab47/ZXy5z587tsrR/+/btMmbMGBERqa2tlfLycqfP2tvbZe3atRdsn508ebJL9c9+/fpJZ2eniLDPspL2KohsPP7449HAgQOjH/zgB9GWLVuiT3/609Hw4cOj5ubmtJuWF3z2s5+NiouLo2eeeSbav39//N/JkyfjfT7zmc9ENTU10a9//etow4YN0Zw5c6I5c+ak2Or8Qq+CiyL2F7Ju3bqof//+0b333hvt2LEjevTRR6MhQ4ZE//7v/x7vc//990fDhw+Pfvazn0WvvPJKdMMNN1zQS4oXLVoUjR49Ol6G/V//9V9RaWlpdNttt8X7sM9c8nICiqIo+va3vx3V1NREAwYMiGbNmhW9+OKLaTcpbxCRrP89/PDD8T6nTp2KPve5z0UjRoyIhgwZEv3VX/1VtH///vQanWfgBMT+6sp///d/R1OmTIkGDhwY1dXVRd/97ned7Z2dndGdd94ZZTKZaODAgdG1114bNTQ0pNTa9Glvb49uueWWqKamJho0aFA0bty46J/+6Z+i06dPx/uwz1xYD4gQQkgq5J0GRAgh5MKAExAhhJBU4ARECCEkFTgBEUIISQVOQIQQQlKBExAhhJBU4ARECCEkFTgBEUIISQVOQIQQQlKBExAhhJBU4ARECCEkFf4vt2ALxv0byU0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxj0ImCCJ-cO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}